{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Activation\n",
    "import  pandas as pd\n",
    "import  os\n",
    "from keras.models import Sequential, load_model\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras import backend as K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n",
      "()\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Tensor(\"sequential_5/dense_23/Softmax:0\", shape=(None, 3), dtype=float32)\n",
      "Tensor(\"sequential_5/dense_23/Softmax:0\", shape=(None, 3), dtype=float32)\n",
      "12/12 [==============================] - 1s 2ms/step - loss: 0.6136\n",
      "Epoch 2/10\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.6120\n",
      "Epoch 3/10\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.6114\n",
      "Epoch 4/10\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.6114\n",
      "Epoch 5/10\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.6114\n",
      "Epoch 6/10\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.6114\n",
      "Epoch 7/10\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.6114\n",
      "Epoch 8/10\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.6114\n",
      "Epoch 9/10\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6114\n",
      "Epoch 10/10\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.6114\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_train = 3.14*np.arange(360)/180\n",
    "y_train = np.sin(x_train)\n",
    "\n",
    "model =  Sequential()\n",
    "model.add(Dense(units=32, activation='relu', input_shape=(1,)))\n",
    "model.add(Dense(units=64, activation='relu'))\n",
    "model.add(Dense(units=32, activation='relu'))\n",
    "model.add(Dense(units=3,activation=tf.nn.softmax))\n",
    "# model.add(Activation('softmax'))\n",
    "def my_loss(y_true, y_pred):\n",
    "    # y is an one-hot vector\n",
    "    print(y_pred)\n",
    "    yp = y_pred[0]\n",
    "    return K.mean(K.square(yp - y_true), axis=-1)\n",
    "\n",
    "model.compile(optimizer='adam', loss=my_loss)\n",
    "\n",
    "model.fit(x=x_train, y=y_train, epochs=10)\n",
    "\n",
    "y_pred = model.predict(x=x_train)\n",
    "plt.plot(x_train, y_pred)\n",
    "plt.plot(x_train, y_train)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.5514\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4218\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3729\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3344\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2998\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2685\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2462\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2170\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1890\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1754\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1713\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1546\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1389\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1322\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1306\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1260\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.1232\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.1253\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1256\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1235\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1198\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1207\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1181\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1158\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1219\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1156\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1106\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1103\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1124\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1127\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1087\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1024\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1065\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0986\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0994\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0976\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0941\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0923\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0952\n",
      "Epoch 40/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0934\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0981\n",
      "Epoch 42/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0871\n",
      "Epoch 43/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0848\n",
      "Epoch 44/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0846\n",
      "Epoch 45/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0833\n",
      "Epoch 46/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0864\n",
      "Epoch 47/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1064\n",
      "Epoch 48/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1037\n",
      "Epoch 49/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0952\n",
      "Epoch 50/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0752\n",
      "Epoch 51/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0748\n",
      "Epoch 52/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0730\n",
      "Epoch 53/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0698\n",
      "Epoch 54/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0699\n",
      "Epoch 55/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0664\n",
      "Epoch 56/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0661\n",
      "Epoch 57/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0631\n",
      "Epoch 58/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0613\n",
      "Epoch 59/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0596\n",
      "Epoch 60/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0619\n",
      "Epoch 61/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0597\n",
      "Epoch 62/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0615\n",
      "Epoch 63/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0576\n",
      "Epoch 64/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0551\n",
      "Epoch 65/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0510\n",
      "Epoch 66/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0526\n",
      "Epoch 67/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0502\n",
      "Epoch 68/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0498\n",
      "Epoch 69/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0494\n",
      "Epoch 70/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0451\n",
      "Epoch 71/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0413\n",
      "Epoch 72/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0397\n",
      "Epoch 73/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0383\n",
      "Epoch 74/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0372\n",
      "Epoch 75/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0346\n",
      "Epoch 76/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0343\n",
      "Epoch 77/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0333\n",
      "Epoch 78/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0385\n",
      "Epoch 79/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0391\n",
      "Epoch 80/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0403\n",
      "Epoch 81/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0308\n",
      "Epoch 82/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0275\n",
      "Epoch 83/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0250\n",
      "Epoch 84/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0229\n",
      "Epoch 85/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0228\n",
      "Epoch 86/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0212\n",
      "Epoch 87/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0190\n",
      "Epoch 88/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0195\n",
      "Epoch 89/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0183\n",
      "Epoch 90/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0192\n",
      "Epoch 91/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0147\n",
      "Epoch 92/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0136\n",
      "Epoch 93/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0133\n",
      "Epoch 94/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0140\n",
      "Epoch 95/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0122\n",
      "Epoch 96/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0111\n",
      "Epoch 97/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0101\n",
      "Epoch 98/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0093\n",
      "Epoch 99/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0085\n",
      "Epoch 100/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0118\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD4CAYAAADhNOGaAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAA6zklEQVR4nO3dd3RU1drH8e+TXighECCEhARI6D303quADQQbiuWK2EC9WK56ERT0IliwYEFUFLGCBekgqCChdxJCCTWhl5CQst8/zuAbMZSQSU4m83zWmsXMmXPm/Oa67jzZZ++ztxhjUEop5b487A6glFLKXloIlFLKzWkhUEopN6eFQCml3JwWAqWUcnNedge4FuXKlTORkZF2x1BKKZeyevXqI8aYkIu3u2QhiIyMJC4uzu4YSinlUkRkT27b9dKQUkq5OS0ESinl5rQQKKWUm9NCoJRSbk4LgVJKuTmnFAIR+UhEkkVk0yXeFxF5Q0QSRGSDiDTO8d6dIhLveNzpjDxKKaWunrNaBB8DPS7zfk8g2vG4D3gHQESCgeeB5kAz4HkRKeOkTEoppa6CU+4jMMb8KiKRl9mlH/CJsea8XiEiQSISCnQA5htjjgGIyHysgvKFM3KpPMpMh6M74cgOSD0C6aetbd4B4FsCSoVBuRgIigAPT7vTKqWcpLBuKAsDknK83ufYdqnt/yAi92G1JoiIiCiYlO4mOxv2/gE7F0LiEjiwDkzWlY/zDoCIFhDVHmJ6QPmaBZ1UKVWAXObOYmPMFGAKQGxsrK6mkx8n9sLqabDhSziZBOIJlWOh9SNQvjaExECJiuBbkmwPH44eP45P9llKpx+yWguHNsKuX2HB89YjtCE0HAwNBoFfKbu/nVIqjwqrEOwHwnO8ruzYth/r8lDO7UsKKZP7SdkOyyfChpmAgaodMZ2fJzG4DQt2prJwWzKJK86QmX2YrOxDZGcb0jOzycy26m7VcoE0imhA4yrtadzoP8QEnMFz6yxY/wXMeRIWj4Wm90KLByCwnL3fVSl11cRZS1U6+gh+NMbUzeW93sBwoBdWx/Abxphmjs7i1cCFUURrgCYX+gwuJTY21uhcQ3lw9ggsetFqBXj7k9XoDtZUupU5SV4s3HaYPUdTAagVWoqG4aXx9vTAQwRPD8HXy4PQ0n6cTs9kzZ4TrN17nKNnzwMQ6ONJg/AgbmxcmesrJOPx20TY+gP4lIB2I6HFMPDytfObK6VyEJHVxpjYf2x3RiEQkS+w/rIvBxzGGgnkDWCMeVdEBHgLqyM4FbjLGBPnOPZu4GnHR401xky90vm0EFyl7GyI+xAWvggZZznb8G4mZ/Rj2voznD2fhY+XB62qlaVzrQp0qlmesCD/K36kMYa9x1JZs/c4a/ac4I/EoyQkn6FB5dI8d10dmgQkw/znYcccKBMJfSZCtU4F/12VUldUoIWgsGkhuAon9sL3w2D3MlLD2/OO3728t9WLrGxDvwaV6FUvlFbVyxLgk7+rg9nZhu/X7WfcnG0kn06nf8NK/LtnTUJTfoc5/4aj8RB7N3R90Rp5pJSyjRYCd7L5O5j1EAb4tepj3LOxJh7iwY1NKvOvdtWIKBvg9FOeTc/knSU7mbIsEU8RHuhQjftahuK37GX4Y7LVOhjwCYTWd/q5lVJXRwuBO8jKsC7LrJhMduWmvBr4BO+sz6Rn3YqM7leXkJIFf70+6VgqL/28lTmbDhEW5M9TvWrSu9Qu5Jt74Nwx6P0aNLq1wHMopf7pUoVA5xoqLs4dh0+vhxWTSW9yL3fzAu+sz+ShTtV5+9bGhVIEAMKDA3jntiZ8cW8LSvp5MfzztQz8xYNt/X+E8GYwa5h1ySj7Ku5XUEoVCi0ExcHxPfBhd0hayZGub9An/jqWJ57ilRvrM7JbDay++sLVslpZfnq4LS9dX4+ElDP0nbqDhbHvQYsHYeW78OXtcD610HMppf5JC4GrO7QJPugCZw6xres0ui2qRPLpdD4Z2owBTcOvfHwB8vQQBjePYMGI9tSsWJL7p6/jh9Dh0PMV2P4zTOsDqZcdKayUKgRaCFzZwfXWj6mnN/NafELfH4Qgf2++f7A1raoVnRu6ggN9mH5PcxpHlOHhGWuZIT1h4GfWHcrT+lr3OSilbKOFwFUdWAvT+mJ8Avk4ZjL3/XKW2MgyfDesNVHlAu1O9w8l/byZdncz2kWHMOrbjXxwpDYM/hKOJsDUXnD6kN0RlXJbWghc0f7VMK0fxq8U70S9wQvLU7mhURjT7m5G6QBvu9Ndkr+PJ+/fEUvPuhUZ89NWJu2qjLn1Kzi1Hz7pp5eJlLKJFgJXk7IdPrsR4x/Ea2ETeWVFGrc2j+B/NzfA27Po/+f08fLgzUGNuKlJZSYtiGfs5rKYQV/AsV0w/SZr6mulVKEq+r8c6v+d3A+f3oDx8GZcyHjeXJ3OvW2jGNO/Lh4ehT8y6Fp5eXrwyo31ubNlFT5Yvosxm8thbp5qTYM9YzBkpNkdUSm3ooXAVZw7brUE0k4yruxY3tuYzSOdo3m6Vy1bhofml4eH8ELfOgxpFcmHy3cxJiEK0/9ta3rrb4bqfQZKFSItBK4gIw2+GIQ5tpP/BT/PezsCeapnTR7rGuOSReACEeH562r/VQzGJtXHdH8Ztv1orXOglCoULrMwjdsyBn58DPb+wVtln2Xy7kq82K8Ot7eMtDuZU1woBgAfLN9F2HU9uavpTvj9TWtZzMZ32JxQqeJPWwRF3R+TYf3nfFniNiYeqM3/bm5QbIrABSLCc31q06VWeV76eSvr6j4FVTtaBXD3crvjKVXsaSEoyhIWYOb/h998WvPssZ684RhtUxx5eAj/u7kB5Uv68eAXGzjZ5wMIrgpf3gbHEu2Op1SxpoWgqDqSgPnqLnZ7RjIs9V7evb0pfepXsjtVgQoK8OGtwY1IPp3GyB92YwbNAJMNM++AjHN2x1Oq2HJKIRCRHiKyXUQSRGRULu9PFJF1jscOETmR472sHO/NdkYel3c+FWbeQVq2B7edeYTRNzWjc60KdqcqFI0iyjCqZy0WbD3M1K0ecP0UayqKOU/aHU2pYivfhUBEPIHJQE+gNjBIRGrn3McY85gxpqExpiHwJvBtjrfPXXjPGNM3v3mKhV/+DcmbefDcAzSoV4++DYp3S+Bid7eOpEut8rw8ZysbA1tCmxGw5hNYO93uaEoVS85oETQDEowxicaY88AMoN9l9h8EfOGE8xZP67+ENZ8w038A632b8GK/ui49RPRaiAiv3tSAciV8Gf7FGk63ehIi28JPI6zWgVLKqZxRCMKApByv9zm2/YOIVAGigEU5NvuJSJyIrBCR/pc6iYjc59gvLiUlxQmxi6CU7fDjo+wv1Zinjl/HmP51KVuicBaUKWrKBPrw+i2NSDqWyjOztmFu/BD8guCrIXD+rN3xlCpWCruz+Bbga2NMzttGqziWThsMTBKRarkdaIyZYoyJNcbEhoSEFEbWwpWRBl/dRaanPwOODqVXg3B61gu1O5WtmkUF81iXGGavP8BX287DDVPg6E6Y+4zd0ZQqVpxRCPYDOVdAqezYlptbuOiykDFmv+PfRGAJ0MgJmVzPohcheTOjvR4i3b8io/vWsTtRkTCsY3VaVSvLc7M3ER/YGFo9BKunwraf7I6mVLHhjEKwCogWkSgR8cH6sf/H6B8RqQmUAf7Isa2MiPg6npcDWgNbnJDJtSQuhT/eYn3oTXxyJIaXrq9LmUAfu1MVCZ4ewqSBDQn0sdY/Tmv7FFSsD7OG6xoGSjlJvguBMSYTGA7MBbYCM40xm0VktIjkHAV0CzDDGGNybKsFxInIemAxMM4Y416F4NwJ+H4Y6aWrctue3lzfKIxudSranapIKV/KjwkDGrD98Gn+O2cn3PiBdV/Bd/+C7Gy74ynl8pwy15Ax5mfg54u2PXfR6xdyOe53oJ4zMrisn5/AnD7IE4Gv4BdY6q95d9TfdahRnvvbV+W9pYm0rt6IPt3HwE8jrctETYfaHU8pl6Z3Fttpy2zYOJPfw4Yy+0goL19fj6AAvSR0KY93q0GjiCCe+mYje6MGQdUOMP85OL7H7mhKuTQtBHY5dxx+GklqcB3u2tmGm5pUpktt97h7+Fp5e3rwxi2NEIGHZqzlfK/XrTdmP2TN0qqUuiZaCOwy91lM6lGGpw6lfFBJvSR0lcKDA3jlpvqs33eSV1emQtfRsGsprP7Y7mhKuSwtBHbYuQjWfcbicoNZfLIiEwc2pKRf0V10vqjpUTeU21tU4f1lu1hUojdEtYN5z8KJvXZHU8olaSEobOln4IdHOFsyigeSOvOv9tVoGhlsdyqX80zvWtQKLcXIrzaQ0nGCdWnop5F6iUipa6CFoLAtGgMn9vLw2bupXqkcj3WJsTuRS/Lz9uStwY1Iz8zm0XnHMB2fgvh5sGWW3dGUcjlaCApT0irMyndZWLIfy85HM2lgQ3y89D/BtaoWUoKnetXit4Sj/OjfDyrWg19GQdopu6Mp5VL0V6iwZGXCj4+S6leeh1P6MqpHTaIrlLQ7lcsb3CyCemGlGTNnB6ndJ1h3Gy8aY3cspVyKFoLCsup9OLyJp1JvpVH1cIa0irQ7UbHg6SGM7leHw6fSmbS1FDS9B/6cAvtX2x1NKZehhaAwnD6EWTSWNT5NWOLRnFdvro+Hh3utMVCQGkWU4Zam4Xy0fBcJ9R6DEhXgh0etVphS6oq0EBSGec+SlZHOY6dvZcz19Qkt7W93omLnyR41CfT14tlf9mJ6jINDG6yWgVLqirQQFLRdv8LGr3g38zrq1mvkdstOFpbgQB+e7FGDFYnHmJ3RFKp3gcUvwenDdkdTqsjTQlCQMs9jfnqcQx4VmO59g64xUMBuaRpB/cqlGfvzNs50GgOZabBwtN2xlCrytBAUpBVvI0e281TaHTzTv7HbLjtZWDw9hBf71SXlTDoT1xhoOQzWfQb7tONYqcvRQlBQTh8me+krLDJN8KnVg95uvuxkYWkQHsQtTcOZ9vtuEmsPszqO5zyh6xYodRlOKQQi0kNEtotIgoiMyuX9ISKSIiLrHI97crx3p4jEOx53OiNPkbDoRbIz0xmbcSvP9KqNiI4SKiwju9XAz9uTlxYkWZPS7V8N67+48oFKual8FwIR8QQmAz2B2sAgEcltKs0vjTENHY8PHMcGA88DzYFmwPMiUia/mWx3cD1m7Wd8nNmd1s2bE1E2wO5EbqVcCV8e7FidBVuT+S2gE1RuCgtegLSTdkdTqkhyRougGZBgjEk0xpwHZgD9rvLY7sB8Y8wxY8xxYD7QwwmZ7GMM/PI0ZzxL8b7cyEOdou1O5Jbuah1JWJA/Y37eTlb38XA2BZa+YncspYokZxSCMCApx+t9jm0Xu1FENojI1yISnsdjXcfWH2DPcsan3cCANnUJKakdxHbw8/ZkVM+abD14im8OlYdGt8HKd+HoTrujKVXkFFZn8Q9ApDGmPtZf/dPy+gEicp+IxIlIXEpKitMDOkVmOsz/D/u8I5nj051721W1O5Fb61M/lMYRQbw6bztn24wCT1/rEpFS6m+cUQj2A+E5Xld2bPuLMeaoMSbd8fIDoMnVHpvjM6YYY2KNMbEhISFOiF0AVr4Lx3cz6uwg/tWxBqV0sRlbiQjP9qlNyul03l19Flo/Altnw96VdkdTqkhxRiFYBUSLSJSI+AC3ALNz7iAiOcdO9gW2Op7PBbqJSBlHJ3E3xzbXcyYZs/RV/vRpxs6STbm9ZRW7EymgcUQZ+jaoxJRfEzlc9x4oURHmPaML2CiVQ74LgTEmExiO9QO+FZhpjNksIqNFpK9jt4dFZLOIrAceBoY4jj0GvIhVTFYBox3bXM/isZiMc4w6PYBHu0Tj5+1pdyLl8ET3GmRlG97+7SB0ehb2rYIt39sdS6kiQ4wL/mUUGxtr4uLi7I7x/1K2Y95uwffevXjL917mPtoOL0+9V68oGfXNBr5ds5+lj7cl9ItukHEWHvwTvLQzX7kPEVltjIm9eLv+WjnDwtFkevrz4qk+PNY1RotAEfRgx+pkG8PbS3dDt9FwfDes+sDuWEoVCfqLlV97V8K2H5nu2Z+y5SvRq65OJVEUhQcHcHNsOF+uSuJAudZQrZN1X8G543ZHU8p2WgjywxiY/xxpfiGMP9mZ4Z2q64IzRdjwTtUxGCYvToCuL1p3Gv/6P7tjKWU7LQT5sX0OJK1giscAQsuVpU99XWugKAsL8mdAbDgz45LY51sVGt1qLV5zfI/d0ZSylRaCa5WVCQv/y9kSkbxxrDnDOlbHU1sDRd6DHasjCJMX74QOTwMCS8bZHUspW2khuFbrv4CUbYzPGEBEudL0a6itAVdQKcifgU3D+SouiaSsMtDsXtgwA5K32R1NKdtoIbgWGedg8UscKlmXT0424L/96uCtI4VcxrCO1fAQsfoK2owA70BYPMbuWErZRn+9rsXK9+D0AR4/fgO961WibXQRnfJC5Sq0tD+DmoXz9ep9JKX7Q6vh1mSB+3UlM+WetBDk1bkTsPw1Nvg3Y41HHZ7tU8vuROoaDOtojfB6c1E8tHwQAsrq+sbKbWkhyKs/3oK0k4w60Z9Hu0QTWtrf7kTqGlQo5cfgZhF8s2Y/e854QNuRkLgEEpfaHU2pQqeFIC/OHsH88TbzpBVeYQ24u3WU3YlUPgzrUA0vD+HNRQkQOxRKVYaF/9UJ6ZTb0UKQF8snYjLO8dr5G3jlpvo6lYSLK1/Kj1ubV+G7tfvZfTILOvzb6ifY9pPd0ZQqVPpLdrVOHSTrz/f5Lqs1PTt2oGbFUnYnUk7wrw5V8fYU3lgUDw0GQ9loWPQiZGfZHU2pQqOF4CqlL34Fk5XJD0F38ECHanbHUU5SvqQftzWvwvdr95N4LA06PQMp22DjV3ZHU6rQaCG4Gsf34LXuE2ZmdeDxW7rj46X/sxUn97evho+Xh9VXUKsfhDaAxWMh87zd0ZQqFPqLdhUyFo0jM1vYUv1+6oaVtjuOcrKQkr7c0TKSWev2s/NoKnT6D5zYC+um2x1NqULhlEIgIj1EZLuIJIjIqFzeHyEiW0Rkg4gsFJEqOd7LEpF1jsfsi4+13ZEEPDfO4LOsLgzo3NzuNKqA3NeuKr5enryxMB6qd4HKTWHZBMhMv/LBSrm4fBcCEfEEJgM9gdrAIBGpfdFua4FYY0x94GvglRzvnTPGNHQ8+lLEZC8eSzre/Bl2B/UrB9kdRxWQciV8uaNVFWavP0BCyhno+DScTIK1n9odTakC54wWQTMgwRiTaIw5D8wA+uXcwRiz2BiT6ni5AqjshPMWvEOb8Nj8LR9ldmdgxyZ2p1EF7P521fD39uT1hQlQtSOEt4BfJ0BGmt3RlCpQzigEYUBSjtf7HNsuZSgwJ8drPxGJE5EVItL/UgeJyH2O/eJSUlLyFfhqmSUvcVYCmB80gA4x5QvlnMo+wYE+3Nkqkh83HCA+2dEqOH0A1kyzO5pSBapQO4tF5DYgFng1x+YqjsWUBwOTRCTXsZnGmCnGmFhjTGxISCFM8nZwPbLtJ6ac78nAdg105TE3cV/bqgR4e/L6wniIagdV2sCy16wZZ5UqppxRCPYD4TleV3Zs+xsR6QI8A/Q1xvzVA2eM2e/4NxFYAjRyQqb8W/oKqRLI9759ub7R5Ro4qjgpE+jDkNaR/LTxIDuSz0DHp+DMIYibanc0pQqMMwrBKiBaRKJExAe4Bfjb6B8RaQS8h1UEknNsLyMivo7n5YDWwBYnZMqfgxtg24+8d74H17eqjZ+3p92JVCG6t21VAn28eH1BPES2sVoGyyfC+dQrH6yUC8p3ITDGZALDgbnAVmCmMWaziIwWkQujgF4FSgBfXTRMtBYQJyLrgcXAOGOM/YVg6XjOeZRguvTi9hZVrry/KlaCAny4y9Eq2HbolLWk5dlkiPvQ7mhKFQgvZ3yIMeZn4OeLtj2X43mXSxz3O1DPGRmc5tBG2PYjH2TfSNfGNShbwtfuRMoG97Spyse/7eb1BfG8c1tLaxTR8knQ5C7wLWF3PKWcSu8svtjS8aR7BvL++e7c01anmXZXpQO8uatNFHM2HWLLgVPWCKLUI7DqfbujKeV0WghyOrQJtv7AtOxeNKtVlWoh+pefOxvaJoqSfl68vnAHhDez7jj+7Q1IP213NKWcSgtBTkvHc96rBG+d68o9bavanUbZrLS/N0PbRDF382E27T9p9RWcOwYr37U7mlJOpYXggsObYetsZkgvqoSF0Twq2O5Eqgi4u00Upfy8mLRgB1RuAtHd4fe3IO2U3dGUchotBBcsHU+mVyATTnfhnrZRiOgNZApK+Xlzf/tqLNiazNq9x6HDKEg7AX++Z3c0pZxGCwHA4S2wZRbfeF9H6eDy9K4XanciVYQMaRVJcKAPr83fAWGNIaaHtgpUsaKFAP5qDbx0vJO1oLmuRaxyCPT1YliHaiyLP8KKxKPQ/t/aKlDFiv7iHd6C2TKL732vI7B0OW5o7BoTo6rCdVuLKpQv6ctr83ZgKjXSVoEqVrQQ/PoK2V4BjDnakX91qKbLUKpc+Xl78lCn6vy5+xjLE45oX4EqVtz7Vy95K2bz98zyvQ7vkuUYEBt+5WOU2xrQNJywIH/+N28HJrQhxPR0tApO2h1NqXxx70Kw9BWyvPwZfbQjj3aJ1snl1GX5ennycOfqrE86wcKtydDB0Vewcord0ZTKF/ctBMnbMJu/49PsHlQJD+eWphF2J1Iu4IbGlYksG8CE+TvIrtjQahX8oa0C5drctxD8+ioZHn68ea4bY/rVxVMXnlFXwdvTg0e7xLD14CnmbDqkrQJVLLhnIUjZjtn0DR+e70qfFvWoV7m03YmUC7muQSWiy5fgtfnbydJWgSoG3LIQmKWvkia+fO3bn5HdatgdR7kYTw9hRNcYdqacZda6/doqUC7P/QpByg7Y9DUfZ3Tlwd7NKe3vbXci5YK616lInUqlmLQgnowKDaBGL20VKJfllEIgIj1EZLuIJIjIqFze9xWRLx3vrxSRyBzvPeXYvl1Eujsjz+WkLxpPGj7EVbpV1yJW18zDQxjZLYa9x1L5ZvW+/7/beKXeV6BcT74LgYh4ApOBnkBtYJCI1L5ot6HAcWNMdWAiMN5xbG2sNY7rAD2Atx2fVzCOxOO99Vs+yerGv29soxPLqXzpWKM8jSKCeGNhPOnl62mrQLksZ7QImgEJxphEY8x5YAbQ76J9+gHTHM+/BjqL9SvcD5hhjEk3xuwCEhyfVyD2fv9f0ow355s9SEyFkgV1GuUmRISRXWtw4GQaM/5McrQKTmqrQLkcZxSCMCApx+t9jm257uNY7P4kUPYqjwVARO4TkTgRiUtJSclzSGMMC9Nr8nWpO3igV/M8H69UblpXL0vzqGDeWpzAuXLaKlAFyBjISCuQj3aZzmJjzBRjTKwxJjYkJCTPx4sIdzzwDP2GvayziyqnERFGdqtByul0Pl2xW1sFquDs+hUm1YODG5z+0c74RdwP5Jykp7JjW677iIgXUBo4epXHOo2nh+goIeV0zaKCaRcTwjtLdnKmbF1tFaiCsXQ8eHhCuRinf7QzCsEqIFpEokTEB6vzd/ZF+8wG7nQ8vwlYZIwxju23OEYVRQHRwJ9OyKRUoRrZNYbjqRlMXb7LMTOptgqUE+1aBnt+g9aPgref0z8+34XAcc1/ODAX2ArMNMZsFpHRItLXsduHQFkRSQBGAKMcx24GZgJbgF+AB40xWfnNpFRhaxAeRNfaFZiyLJGTpWtDjd5Wq+DcCbujqeJg6XgoURGa3Hnlfa+BUy6WG2N+NsbEGGOqGWPGOrY9Z4yZ7XieZoy52RhT3RjTzBiTmOPYsY7jahhj5jgjj1J2GNE1htNpmXywPNFxt7G2CpQT7F4Ou5dBm0fB279ATqG9pko5Sa3QUvSpH8pHy3dxtGRNq1WwYrK2ClT+LBkHJSpAkyEFdgotBEo50aNdYjiXkcV7v2qrQDnBnt+t1kDrRwqsNQBaCJRyqurlS9C/URjTft9NcmANbRWo/FkyDgLLQ5O7CvQ0WgiUcrJHOkeTlW2YvDhBWwXq2u1dAbuWQuuHwSegQE+lhUApJ6tSNpCbY8P5/M+97POLhpp9tFWg8m7JOAgoB7F3F/iptBAoVQAe6lQdQXhrUQK0f9LRKnjX7ljKVexdCYmLrb4Bn8ACP50WAqUKQKUgfwY3j+Cr1fvY7V3dahX88ba2CtTVWepoDTQdWiin00KgVAEZ1rEa3p7CGwvjrVZBurYK1FVIWgU7F0GrhwqlNQBaCJQqMOVL+nFny0i+W7efeI+q2ipQV2fpOAgoC03vKbRTaiFQqgDd374aAd6eTFqgrQJ1FfathoQF0HI4+JYotNNqIVCqAAUH+jC0TRQ/bTzIZhOprQJ1eUvHgX8ZaHZvoZ5WC4FSBWxo26qU8vNi4vwd1noF2ipQudm/GuLnWX0DvoW7gqIWAqUKWGl/b+5vX40FW5NZmxGurQKVu6WvOFoD9xX6qbUQKFUIhrSKJDjQh9dytgpWvGN3LFVU7IuDHb84+gYKfz11LQRKFYJAXy+GdajGsvgjrDwX5rjb+B1tFSjL4rHWSKHm99ty+nwVAhEJFpH5IhLv+LdMLvs0FJE/RGSziGwQkYE53vtYRHaJyDrHo2F+8ihVlN3WogrlS/oyYd4OzIURRNoqUHv+sO4baP2ILa0ByH+LYBSw0BgTDSx0vL5YKnCHMaYO0AOYJCJBOd5/whjT0PFYl888ShVZft6eDO9UnT93H2P5mUraKlCWxWOtGUabFu5IoZzyWwj6AdMcz6cB/S/ewRizwxgT73h+AEgGQvJ5XqVc0sCm4YQF+fO/eTsw2legEpda6w20HVHgM4xeTn4LQQVjzEHH80NAhcvtLCLNAB9gZ47NYx2XjCaKiO9ljr1PROJEJC4lJSWfsZWyh6+XJw93rs76pBMsPF4Bal2nrQJ3ZYzVGihZqcDXG7iSKxYCEVkgIptyefTLuZ8xxgDmMp8TCnwK3GWMyXZsfgqoCTQFgoF/X+p4Y8wUY0ysMSY2JEQbFMp13dC4MpFlA5gwfwfZbbWvwG0lLISkldBuJHj72RrlioXAGNPFGFM3l8cs4LDjB/7CD31ybp8hIqWAn4BnjDErcnz2QWNJB6YCzZzxpZQqyrw9PXi0SwxbD55izpEQR6vgbTh33O5oqrBcaA2UjoBGd9idJt+XhmYDdzqe3wnMungHEfEBvgM+McZ8fdF7F4qIYPUvbMpnHqVcwnUNKhFdvgSvzd9OVtsnIf2UtgrcyY5f4MAaaP8EePnYnSbfhWAc0FVE4oEujteISKyIfODYZwDQDhiSyzDR6SKyEdgIlAPG5DOPUi7B00MY0TWGnSlnmXUoOEdfgbYKir3sbKs1UCYKGgyyOw0AYl3ady2xsbEmLi7O7hhK5Ut2tuG6t5ZzJj2TBYOD8X6/nXXXccen7Y6mCtKWWTDzDuj/LjQs3EIgIquNMbEXb9c7i5WyiYejVbDnaCrf7C+jrQJ3kJ0Fi1+GstFQf4Ddaf6ihUApG3WqWZ6G4UG8sTCe8220r6DY2/wdpGyFDqPAw9PuNH/RQqCUjUSEx7vV4MDJNL7YUwpq9dVWQXGVlWH1DZSvDXVusDvN32ghUMpmrauXpXlUMG8tTiCt9RNWq+C3N+yOpZxt7adwLBE6PwceReunt2ilUcoNiQgju9Ug5XQ6nyQGQr2brVbBqYNXPli5hvOpsGQ8hLeAmB52p/kHLQRKFQHNooJpFxPCO0t2crb1KMjOhKXj7Y6lnGXlu3DmEHR5AUTsTvMPWgiUKiJGdo3heGoGH202EHsXrPkEjiTYHUvl17nj8NskiO4OVVranSZXWgiUKiIahAfRtXYFpixL5FTTR8HLDxaNtjuWyq/lkyDtlNU3UERpIVCqCBnRNYbTaZm8v/YMtBpu3Xy0f7XdsdS1OnXAuixUfwBUrGt3mkvSQqBUEVIrtBS964fy0fJdHKt/n7V84YIXrEnKlOtZOt66iayI3y2uhUCpIuaxLtGcy8ji3ZUp0O5J2PWrtZShci1HEmDNpxB7N5SJtDvNZWkhUKqIqV6+JP0bhTHt990kxwyCoAirVZCdfcVjVRGyaLTVz9PucbuTXJEWAqWKoEc6R5OVbZi8LAk6PguHNsDmb+2Opa7W3hVW/07rh6FEebvTXJEWAqWKoCplA7k5NpzP/9zLvvDeULEeLPgvZKTZHU1diTEw9xkoGQqtHrI7zVXRQqBUEfVQp+oIwluLE6H7S3Byr7WSmSraNn0D++Og03/AJ9DuNFdFC4FSRVSlIH8GN4/gq9X72F2yCdToDctegzO5rgirioKMNKvlVrFekVl05mrkqxCISLCIzBeReMe/ZS6xX1aO1clm59geJSIrRSRBRL50LGuplHIY1rEa3p7CGwvjoetoyDwHi1+yO5a6lJXvWC23bmOL3MRyl5PfpKOAhcaYaGCh43VuzhljGjoefXNsHw9MNMZUB44DQ/OZR6lipXxJP+5sGcl36/YTn1UBmt4La6bB4S12R1MXO3vEarHF9ISq7e1Okyf5LQT9gGmO59OwFqC/Ko4F6zsBFxa0z9PxSrmL+9tXI8Dbk0kL4qH9k+BbCuY9ozeZFTVLXobzZ62WWwHJzCqYIcT5LQQVjDEX5so9BFS4xH5+IhInIitEpL9jW1nghDEm0/F6HxB2qROJyH2Oz4hLSUnJZ2ylXEdwoA9D20Tx08aDbD7haa1rvHMRJCywO5q6IGU7xE2FpkMhJMbpH5+dbfh85V46TlhC8mnnjxy7YiEQkQUisimXR7+c+xljDHCpP1GqOBZMHgxMEpFqeQ1qjJlijIk1xsSGhITk9XClXNrQtlUp5efFxPk7oOk9EFzNGqKYlXnlg1XBm/cf8CkB7S91dfzabTt0ipve/Z2nv9tIpdL+pGc4v1XgdaUdjDFdLvWeiBwWkVBjzEERCQVyHc5gjNnv+DdRRJYAjYBvgCAR8XK0CioD+6/hOyhV7JX29+b+9tV4de521h44S6NuL8KMwbB6KjS71+547m37LxA/F7qNgcCyTvvY1POZvL4gng+W76K0vzf/u7kBNzYOQwpgPYP8XhqaDdzpeH4nMOviHUSkjIj4Op6XA1oDWxwtiMXATZc7XillGdIqkuBAH16bvwNq9IKo9rBojNVJqeyRkQa/jIJyNaD5v5z2sQu3Hqbra7/y3q+J3NS4MgtHtOemJpULpAhA/gvBOKCriMQDXRyvEZFYEfnAsU8tIE5E1mP98I8zxlwY8vBvYISIJGD1GXyYzzxKFVuBvl4M61CNZfFHWLnrGPR6Fc6fseYhUvb44004vgt6jgdP73x/3MGT57j/0ziGTosjwMeTmfe3ZPxN9SkTWLAj68W44MiD2NhYExcXZ3cMpQpdWkYW7V5ZTGTZQL68vwUy/z/w+5twz0KoHGt3PPdyIgneagrRXWHgp/n6qMysbKb9sYfX5m0nyxge7hzNPW2q4uPl3HsRRGS1o7/2b1znjgelFH7engzvVJ0/dx9jecIRawRRiYrw00hr3ntVeOY9a/3bfWy+PmZ90gn6Tf6NF3/cQtOoYOY/1p5hHao7vQhcjhYCpVzMwKbhhAX58795OzA+JaxOyoPrrBvNVOFIXAJbvoe2I61pwq/BqbQMnpu1if5v/0bK6XQmD27M1CFNCQ8OcGrUq6GFQCkX4+vlycOdq7M+6QQLtyZDvZugShtYOBpSj9kdr/jLPA8/P2ktNnMNs4saY/hxwwG6TFjKpyv2cGfLSBaObE/v+qEF1hl8JVoIlHJBNzSuTGTZACbM30G2weo4TjulHceF4ffX4ch26DEevP3ydOjeo6kMmbqK4Z+vpXwpX2Y92JoX+tahpF/+O5rzQwuBUi7I29ODR7vEsPXgKeZsOgQVakOLB6zLQ3t+tzte8XV0Jyx9FWr3hxo9rvqw85nZTF6cQNeJS1m95zjP9anN98NaU79yUIFFzQstBEq5qOsaVCK6fAkmLthBVraxFkgPioDZD+sCNgXBGPjhEWv5yZ7jr/qwlYlH6fXGMl6du51ONcuzYER77m4ThZdn0fn5LTpJlFJ54ukhjOgaQ0LyGWav328tgtJnIhyNh2UT7I5X/Kz7HHYvg64vQMmKV9z92NnzPPHVegZOWUFaRhYfDYnlnduaULF03i4nFYYrTjGhlCq6utepSO3QUkxaEE+f+pXwrt4F6g+E5ROh7g1QvpbdEYuHs0esGV/DW0DjIZfd1RjDV6v38fLPWzmdlsm/2lfjkc7R+Pt4Fk7Wa6AtAqVcmIeHMLJbDHuOpvLN6n3Wxu4vg18pmP2Q3lvgLHOfhvQzcN3rl11wJv7waQa+t4Inv95AtZAS/PRwW0b1rFmkiwBoIVDK5XWqWZ6G4UG8sTCe9Mwsa+Kz7i/DvlWwSmdtybf4BbDhS2g7AsrXzHWXc+ezeHXuNnq9sYwdyacZf2M9Zt7fkhoVSxZy2GujhUApFyciPN6tBgdOpjHjzyRrY/0BUK0zLPwvHN9taz6Xdu44zB4OIbWgzYhcd1myPZluk5YyefFO+jYIY+GI9gxsGoGHhz33BFwLLQRKFQOtq5eleVQwby1O4Nz5LBCxLmMg8P2DkF0wK1sVe3NGwZlkuP6df9wzcPhUGg9+voYhU1fh7enBF/e2YMKABpQt4WtT2GunhUCpYkBEGNmtBimn0/l0xW5rY1A49BwHe5Zbi6qrvNn2E2yYAe0eh0qN/tqclW2Y9vtuukxYyvwthxnZNYY5j7SlZTXnrUVQ2HTUkFLFRLOoYNrFhPDOkp0Mbl6FEr5e0PBW2PojLPivdanoEte41UXOHrXuGahYD9o+/tfmTftP8vR3G9mw7yRto8vxYr+6RJYLtDGoc2iLQKliZGTXGI6nZvD+r4nWhguXiHwC4bv7ISvD3oCuwBj48VE4dwL6vwtePpxOy+CF2Zvp+9ZyDpxI441Bjfjk7mbFogiAFgKlipUG4UH0rh/Ke7/uJOlYqrWxZAXrRrOD62DJOFvzuYQ102DrbOj0LKZCHeZsPEiX15Yy7Y/dDG4ewcKR7enboJJtE8QVhHwVAhEJFpH5IhLv+LdMLvt0FJF1OR5pItLf8d7HIrIrx3sN85NHKQVP9ayJt6cHQ6et4uQ5RwugTn9oeJt1x3HiUlvzFWnJ26wO4qodSKp1D3d/vIoHpq+hbKAv3z7QijH961Ha394J4gpCflsEo4CFxphoYKHj9d8YYxYbYxoaYxoCnYBUYF6OXZ648L4xZl0+8yjl9iqXCeC925qQmHKWYdNXcz7TMWKo1ytQLhq+vRfOpNgbsijKSINvhmJ8AphW4Sm6TlrGyl3HeLZ3LWYPb02jiH/8nVts5LcQ9AMurIYxDeh/hf1vAuYYY1LzeV6l1GW0ql6OcTfW57eEozzz3UaMMVY/wU1TrWvf3z+gQ0ovNv85OLyJZ3mQ5xcfpV10CAtGtOeetlWL1ARxBSG/366CMeag4/khoMIV9r8F+OKibWNFZIOITBSRSw7AFZH7RCROROJSUvSvGaWu5KYmlXm4czRfrd7HW4sSrI0V60KPlyBhPvzxlr0Bi5Cza76CP9/jo8weLMluxPt3xDLljlgqBfnbHa1QXHH4qIgsAHKbau+ZnC+MMUZEzGU+JxSoB8zNsfkprALiA0wB/g2Mzu14Y8wUxz7ExsZe8jxKqf/3WJdoko6lMmH+DiLKBtCvYRjEDrX6CRa8AJUaQlQ7u2PaxhjD/KVLabNkOGuyo0lu8QzzutYm0Ne9RtZfsUVgjOlijKmby2MWcNjxA3/hhz75Mh81APjOGPPX+DVjzEFjSQemAs3y93WUUjmJCONurEfzqGCe+GoDKxOPWkNK+78NZavDV0PgxF67Y9oiIfkMd7+3kGqL/kW6hz8l75jOqD713a4IQP4vDc0G7nQ8vxOYdZl9B3HRZaEcRUSw+hc25TOPUuoivl6eTLk9lsrB/tz36Wp2ppwB35Jwy3TrvoIvb4OMc3bHLDRpGVm8Nm87vV5fwu2HXibKM5nSt39GdPUadkezTX4LwTigq4jEA10crxGRWBH54MJOIhIJhAMXj1ubLiIbgY1AOWBMPvMopXJROsCbj4c0w8tDuGvqKo6eSbdGEN3wPhxcDz88at1IVcwti0+h+6RfeWNRAm9UnEcn4vDoPhaPqDZ2R7OVGBf8jx8bG2vi4uLsjqGUy1m79zi3TFlB7Uql+OLeFvh5e8KS8bDkJej8HLQdaXfEApF8Oo0xP25l9voDRJUL5L368cT8/jg0GGxdJitGN4ddjoisNsbEXry9eI+JUkr9TaOIMkwa2JB1SScYMXMd2dkG2j0B9W6GhaNh/Zd2R3Sq7GzDpyv20HnCUn7ZdIhHOkczt78Qs+Ipq5P8utfdpghcjhYCpdxMz3qhPN2zFj9vPMT4udusFbf6TYbItjDrwWJz5/HmAye54Z3f+c/3m6gXVppfHm3LYw3B5+vbIbgqDPgUvHzsjlkkaCFQyg3d0zaK21pE8N7SRKav3ANevjDwM2sk0Ze3wSHXHbdxNj2TMT9uoe9bv5F0LJWJAxsw/Z7mVPU5AZ/dCJ4+cOtM8A+yO2qR4X7jpJRSiAgvXFeH/cfP8dyszVQK8qdjjfJw29fwQVf4tD8M+QlCXGskzdzNh3hh9mYOnkxjULMIRvWoSekAbzh9CKZdB2kn4M7ZUCbS7qhFirYIlHJTXp4evDW4MTUqlGT49DVsOXAKSle2figR64fzSLzdMa/KvuOp3DMtjvs/XU1pf2++eaAlL99QzyoCZ4/AJ/3g9GG49eu/LTKjLFoIlHJjgb5efDSkKSX9vLn741UcPHnOGlZ65w+QnWUVg6M77Y55SRlZ2Uz5dSddX/uV3xKO8FTPmvzwUBuaVAm2dkg9ZrVuju+GwTMgormdcYssLQRKubmKpf2YeldTzqRncvfHcZxJz7RWMrtzNmSmw8d9rOmZi5jVe45z3ZvLeennbbSuXpb5I9pxf/tqeF+YIO7UQZjaC1J2wMDpbj2VxpVoIVBKUSu0FJNvbcyOw6d5cPoaMrOyoUIdq2VgsmBqD0j60+6YAJxMzeDp7zZy07u/c/JcBu/d3oT374ilcpmA/9/pWCJ81B1OJln9HtFd7AvsArQQKKUAaB8Twov96rJ0RwrPz95sTV1dsS7cPRf8y8C0vrDtZ9vyGWP4bu0+Or+2hBl/7uXu1lHMH9Ge7nUq/n21sL0rrA7v9NNWq0ZbAleko4aUUn8Z3DyCvcdSeXfpTiKCA7i/fTUIjrKKwecDYMZg6PSMtaB7Id6IlZB8hv98v4k/Eo/SIDyIj+9qRt2w0v/ccd0X8MPDVqf34JlWf4e6Ii0ESqm/ebJ7DZKOp/LynG1ULhNA7/qhUKI83DUHZj8Mi8bAoY3Q903wy+XH2InSMrKYvDiBd5fuxN/bkzH96zKoWQSeHhcVoYw0mPcsrHrfagHcPA0Cggs0W3GihUAp9TceHsKEmxtw6GQaj81cR8XSfjSpUga8/eGGKVCxnrWWwYG11qR1ES0KJMeS7ck8N2sze4+lcn2jMJ7uVYuQkrmsXXUkAb4eYhWnlsOhywvgWfzWFS5I2keglPoHP29P3r8jltDSftz7SRx7jp613hCB1g9bl4oQmNoT5j8P5523+uzhU2k8OH0NQ6auwstD+Pye5kwc2PCfRSArE5ZPgnfbwMn91qWg7mO1CFwDnX1UKXVJiSlnuOGd3wkO8OHbYa0ICsgxN0/aKZj7FKz9DEpHQK9XIKbHNfcdZGUbPvljNxPm7eB8VjYPdazOfe2r4uvl+c+d966An5+AQxugRm/oPQFKhV7jt3Qfl5p9VAuBUuqyVu0+xq3vr6RqSCD/7lmTppHBlMi5itfu3+CnEZCyDSJaQsdnIKptns6xPukEz3y/kU37T9EuJoTRfesQWS7wnzse3gKLXoTtP0OJilbxqdVXZxC9SgVSCETkZuAFoBbQzBiT66+ziPQAXgc8gQ+MMRcWsIkCZgBlgdXA7caY81c6rxYCpQrXrztSeHjGWk6kZuDpIdQLK02LqmVpUTWY2MhgSnhmw5ppsGwCnD4I4S2g6VDrR9rb75Kfe/JcBhPmbefTFXsIKeHL89fVoVe9i4aDZmdBwkJY+Q7sXAS+paD1I9DiAfDJpVioSyqoQlALyAbeAx7PrRCIiCewA+gK7ANWAYOMMVtEZCbwrTFmhoi8C6w3xrxzpfNqIVCq8J07n8XqPcdZkXiUFYlHWZd0gsxs87fC0CoigObHf8B39ftwfBf4B0ONXlCjJ1Rtby2RCew/cY5pv+/miz/3cjY9kztaRjKyWwwl/RzX98+fhX2rYOuPsHU2nDkMJUOt4hI7VEcEXaMCvTQkIku4dCFoCbxgjOnueP2U461xQApQ0RiTefF+l6OFQCn7pZ7PZM2eE/yReIQVicdYn6MwNAgrycCyiXQ4N5/yh5Yi6acwCKklI9liolh9sgQppjRRYRXpGFOWsJJe1gyhJ5OsS0yHNll3NHv5Q3RXqHM91Oyj6wfk06UKQWEMHw0DknK83gc0x7ocdMIYk5lje9ilPkRE7gPuA4iIiCiYpEqpqxbg40Wb6HK0iS4HWIXh/1sMx3hmQwiZ2YPw9RhAZ/+dVE/fRN0Tu6jruZHGXsfxNJlwGOsBIJ5QKsy6ga3tCKjcDKq0At8Stn1Hd3HFQiAiC4CKubz1jDFmlvMj5c4YMwWYAlaLoLDOq5S6OgE+XrSNDqFtdAjw/4Xhj51HOXyqClKmN35VyhBSrax1Q9i543D+DHh4WY+AsuCRywghVeCuWAiMMfmdrWk/EJ7jdWXHtqNAkIh4OVoFF7YrpYqBiwvDP3cI1mv9RURh3FC2CogWkSgR8QFuAWYbq3NiMXCTY787gUJrYSillLLkqxCIyPUisg9oCfwkInMd2yuJyM8Ajr/2hwNzga3ATGPMZsdH/BsYISIJWH0GH+Ynj1JKqbzTG8qUUspNXGrUkM41pJRSbk4LgVJKuTktBEop5ea0ECillJvTQqCUUm7OJUcNiUgKsOcaDy8HHHFiHDu4+ndw9fzg+t/B1fODfodrUcUY8487/FyyEOSHiMTlNnzKlbj6d3D1/OD638HV84N+B2fSS0NKKeXmtBAopZSbc8dCMMXuAE7g6t/B1fOD638HV88P+h2cxu36CJRSSv2dO7YIlFJK5aCFQCml3JxbFQIR6SEi20UkQURG2Z0nr0TkIxFJFpFNdme5FiISLiKLRWSLiGwWkUfszpQXIuInIn+KyHpH/v/anelaiYiniKwVkR/tznItRGS3iGwUkXUi4nJTEYtIkIh8LSLbRGSrY812+/K4Sx+BiHgCO4CuWOsjrwIGGWO22BosD0SkHXAG+MQYU9fuPHklIqFAqDFmjYiUBFYD/V3lv4GICBBojDkjIt7AcuARY8wKm6PlmYiMAGKBUsaYPnbnySsR2Q3EGmNc8oYyEZkGLDPGfOBYsCvAGHPCrjzu1CJoBiQYYxKNMeeBGUA/mzPliTHmV+CY3TmulTHmoDFmjeP5aayFisLsTXX1jOWM46W34+Fyf0mJSGWgN/CB3VnckYiUBtrhWIjLGHPeziIA7lUIwoCkHK/34UI/QsWNiEQCjYCVNkfJE8cllXVAMjDfGONS+R0mAU8C2TbnyA8DzBOR1SJyn91h8igKSAGmOi7PfSAigXYGcqdCoIoIESkBfAM8aow5ZXeevDDGZBljGgKVgWYi4lKX6ESkD5BsjFltd5Z8amOMaQz0BB50XDZ1FV5AY+AdY0wj4Cxga5+lOxWC/UB4jteVHdtUIXJcW/8GmG6M+dbuPNfK0ZRfDPSwOUpetQb6Oq6xzwA6ichn9kbKO2PMfse/ycB3WJd+XcU+YF+O1uTXWIXBNu5UCFYB0SIS5eicuQWYbXMmt+LobP0Q2GqMec3uPHklIiEiEuR47o818GCbraHyyBjzlDGmsjEmEuv/A4uMMbfZHCtPRCTQMdgAxyWVboDLjKQzxhwCkkSkhmNTZ8DWARNedp68MBljMkVkODAX8AQ+MsZstjlWnojIF0AHoJyI7AOeN8Z8aG+qPGkN3A5sdFxnB3jaGPOzfZHyJBSY5hiB5gHMNMa45PBLF1cB+M76uwIv4HNjzC/2Rsqzh4Dpjj9KE4G77AzjNsNHlVJK5c6dLg0ppZTKhRYCpZRyc1oIlFLKzWkhUEopN6eFQCml3JwWAqWUcnNaCJRSys39H/vHJ0wOtYNQAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_train = 3.14*np.arange(360)/180\n",
    "y_train = np.sin(x_train)\n",
    "\n",
    "model =  Sequential()\n",
    "model.add(Dense(units=32, activation='relu', input_shape=(1,)))\n",
    "model.add(Dense(units=64, activation='relu'))\n",
    "model.add(Dense(units=32, activation='relu'))\n",
    "model.add(Dense(units=1))\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "model.fit(x=x_train, y=y_train, epochs=100)\n",
    "\n",
    "y_pred = model.predict(x=x_train)\n",
    "plt.plot(x_train, y_pred)\n",
    "plt.plot(x_train, y_train)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-20 10:48:21.104139: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "data=load_iris()\n",
    "iris_target=data.target\n",
    "iris_data=np.float32(data.data)\n",
    "iris_target=np.float32(tf.keras.utils.to_categorical(iris_target,num_classes=3))\n",
    "iris_data=tf.data.Dataset.from_tensor_slices(iris_data).batch(50)\n",
    "iris_target=tf.data.Dataset.from_tensor_slices(iris_target).batch(50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150,)\n",
      "(150, 4)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'BatchDataset' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/kuzaowuwei/Desktop/2022//3/code/DecisionModel.ipynb Cell 7'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kuzaowuwei/Desktop/2022%E7%BE%8E%E8%B5%9B/%E8%B5%9B%E4%B8%AD%E6%95%B0%E6%8D%AE/3%E6%8C%87%E6%A0%87%E4%BD%93%E7%B3%BB/code/DecisionModel.ipynb#ch0000007?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(data\u001b[39m.\u001b[39mtarget\u001b[39m.\u001b[39mshape)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kuzaowuwei/Desktop/2022%E7%BE%8E%E8%B5%9B/%E8%B5%9B%E4%B8%AD%E6%95%B0%E6%8D%AE/3%E6%8C%87%E6%A0%87%E4%BD%93%E7%B3%BB/code/DecisionModel.ipynb#ch0000007?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(data\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mshape)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/kuzaowuwei/Desktop/2022%E7%BE%8E%E8%B5%9B/%E8%B5%9B%E4%B8%AD%E6%95%B0%E6%8D%AE/3%E6%8C%87%E6%A0%87%E4%BD%93%E7%B3%BB/code/DecisionModel.ipynb#ch0000007?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(iris_target\u001b[39m.\u001b[39;49msize)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'BatchDataset' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "\n",
    "print(data.target.shape)\n",
    "print(data.data.shape)\n",
    "print(iris_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss value: tf.Tensor(2.5816584, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.60489297, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(1.3456986, shape=(), dtype=float32)\n",
      "Training loss is: 1.3456986\n",
      "loss value: tf.Tensor(1.9007415, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.7272631, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(1.1432557, shape=(), dtype=float32)\n",
      "Training loss is: 1.1432557\n",
      "loss value: tf.Tensor(1.5098761, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.8455151, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(1.0206523, shape=(), dtype=float32)\n",
      "Training loss is: 1.0206523\n",
      "loss value: tf.Tensor(1.2442976, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.92140466, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.9407256, shape=(), dtype=float32)\n",
      "Training loss is: 0.9407256\n",
      "loss value: tf.Tensor(1.0967357, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.9786774, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.8628363, shape=(), dtype=float32)\n",
      "Training loss is: 0.8628363\n",
      "loss value: tf.Tensor(1.009604, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(1.0073116, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.803412, shape=(), dtype=float32)\n",
      "Training loss is: 0.803412\n",
      "loss value: tf.Tensor(0.9403528, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(1.0151546, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.7612626, shape=(), dtype=float32)\n",
      "Training loss is: 0.7612626\n",
      "loss value: tf.Tensor(0.88119483, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(1.0081764, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.730405, shape=(), dtype=float32)\n",
      "Training loss is: 0.730405\n",
      "loss value: tf.Tensor(0.82808274, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.9901497, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.71325463, shape=(), dtype=float32)\n",
      "Training loss is: 0.71325463\n",
      "loss value: tf.Tensor(0.7778187, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.9637667, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.70338106, shape=(), dtype=float32)\n",
      "Training loss is: 0.70338106\n",
      "loss value: tf.Tensor(0.7263075, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.9356393, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.69537497, shape=(), dtype=float32)\n",
      "Training loss is: 0.69537497\n",
      "loss value: tf.Tensor(0.689575, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.9122847, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.67975545, shape=(), dtype=float32)\n",
      "Training loss is: 0.67975545\n",
      "loss value: tf.Tensor(0.6541778, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.8984258, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.6556502, shape=(), dtype=float32)\n",
      "Training loss is: 0.6556502\n",
      "loss value: tf.Tensor(0.61760473, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.8909906, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.627963, shape=(), dtype=float32)\n",
      "Training loss is: 0.627963\n",
      "loss value: tf.Tensor(0.58019704, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.88606966, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.60259056, shape=(), dtype=float32)\n",
      "Training loss is: 0.60259056\n",
      "loss value: tf.Tensor(0.5433605, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.8790861, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.58386916, shape=(), dtype=float32)\n",
      "Training loss is: 0.58386916\n",
      "loss value: tf.Tensor(0.5077075, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.8676469, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.57201874, shape=(), dtype=float32)\n",
      "Training loss is: 0.57201874\n",
      "loss value: tf.Tensor(0.4722839, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.8522502, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.5644537, shape=(), dtype=float32)\n",
      "Training loss is: 0.5644537\n",
      "loss value: tf.Tensor(0.43707708, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.8361719, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.55883145, shape=(), dtype=float32)\n",
      "Training loss is: 0.55883145\n",
      "loss value: tf.Tensor(0.40221015, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.8211664, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.5531761, shape=(), dtype=float32)\n",
      "Training loss is: 0.5531761\n",
      "loss value: tf.Tensor(0.36772874, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.8076787, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.54694635, shape=(), dtype=float32)\n",
      "Training loss is: 0.54694635\n",
      "loss value: tf.Tensor(0.33466807, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.7962587, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.53929424, shape=(), dtype=float32)\n",
      "Training loss is: 0.53929424\n",
      "loss value: tf.Tensor(0.30412206, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.7860863, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.5302911, shape=(), dtype=float32)\n",
      "Training loss is: 0.5302911\n",
      "loss value: tf.Tensor(0.2764417, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.7764927, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.52082884, shape=(), dtype=float32)\n",
      "Training loss is: 0.52082884\n",
      "loss value: tf.Tensor(0.25133336, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.7675645, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.511595, shape=(), dtype=float32)\n",
      "Training loss is: 0.511595\n",
      "loss value: tf.Tensor(0.22861557, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.7589853, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.5029411, shape=(), dtype=float32)\n",
      "Training loss is: 0.5029411\n",
      "loss value: tf.Tensor(0.20817913, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.74978614, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.49517956, shape=(), dtype=float32)\n",
      "Training loss is: 0.49517956\n",
      "loss value: tf.Tensor(0.1892402, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.7396452, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.48856467, shape=(), dtype=float32)\n",
      "Training loss is: 0.48856467\n",
      "loss value: tf.Tensor(0.1701989, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.7291284, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.48262727, shape=(), dtype=float32)\n",
      "Training loss is: 0.48262727\n",
      "loss value: tf.Tensor(0.1520921, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.7323998, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.47425878, shape=(), dtype=float32)\n",
      "Training loss is: 0.47425878\n",
      "loss value: tf.Tensor(0.13764112, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.7132833, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.4734854, shape=(), dtype=float32)\n",
      "Training loss is: 0.4734854\n",
      "loss value: tf.Tensor(0.12584569, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.69432294, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.4706499, shape=(), dtype=float32)\n",
      "Training loss is: 0.4706499\n",
      "loss value: tf.Tensor(0.114997104, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.68299085, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.46614915, shape=(), dtype=float32)\n",
      "Training loss is: 0.46614915\n",
      "loss value: tf.Tensor(0.104833625, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.67277265, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.46064156, shape=(), dtype=float32)\n",
      "Training loss is: 0.46064156\n",
      "loss value: tf.Tensor(0.09549584, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.6630871, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.45447358, shape=(), dtype=float32)\n",
      "Training loss is: 0.45447358\n",
      "loss value: tf.Tensor(0.08699895, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.6532053, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.44840828, shape=(), dtype=float32)\n",
      "Training loss is: 0.44840828\n",
      "loss value: tf.Tensor(0.07933245, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.6425574, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.4427774, shape=(), dtype=float32)\n",
      "Training loss is: 0.4427774\n",
      "loss value: tf.Tensor(0.07248218, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.6311435, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.43802726, shape=(), dtype=float32)\n",
      "Training loss is: 0.43802726\n",
      "loss value: tf.Tensor(0.06637633, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.6186843, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.43420845, shape=(), dtype=float32)\n",
      "Training loss is: 0.43420845\n",
      "loss value: tf.Tensor(0.0608981, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.60571116, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.4311026, shape=(), dtype=float32)\n",
      "Training loss is: 0.4311026\n",
      "loss value: tf.Tensor(0.056056324, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.592407, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.42828804, shape=(), dtype=float32)\n",
      "Training loss is: 0.42828804\n",
      "loss value: tf.Tensor(0.05178337, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.57950217, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.42485023, shape=(), dtype=float32)\n",
      "Training loss is: 0.42485023\n",
      "loss value: tf.Tensor(0.047970656, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.5674028, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.42072472, shape=(), dtype=float32)\n",
      "Training loss is: 0.42072472\n",
      "loss value: tf.Tensor(0.0445446, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.55606973, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.41614604, shape=(), dtype=float32)\n",
      "Training loss is: 0.41614604\n",
      "loss value: tf.Tensor(0.041373026, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.54521894, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.4112236, shape=(), dtype=float32)\n",
      "Training loss is: 0.4112236\n",
      "loss value: tf.Tensor(0.038425416, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.5347127, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.40597284, shape=(), dtype=float32)\n",
      "Training loss is: 0.40597284\n",
      "loss value: tf.Tensor(0.035694078, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.5241712, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.40072373, shape=(), dtype=float32)\n",
      "Training loss is: 0.40072373\n",
      "loss value: tf.Tensor(0.033234812, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.5137215, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.39534652, shape=(), dtype=float32)\n",
      "Training loss is: 0.39534652\n",
      "loss value: tf.Tensor(0.031102754, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.5037732, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.38941592, shape=(), dtype=float32)\n",
      "Training loss is: 0.38941592\n",
      "loss value: tf.Tensor(0.029293647, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.4944705, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.38314992, shape=(), dtype=float32)\n",
      "Training loss is: 0.38314992\n",
      "loss value: tf.Tensor(0.027754527, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.48560742, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.37674415, shape=(), dtype=float32)\n",
      "Training loss is: 0.37674415\n",
      "loss value: tf.Tensor(0.026420966, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.47698864, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.3703691, shape=(), dtype=float32)\n",
      "Training loss is: 0.3703691\n",
      "loss value: tf.Tensor(0.025241034, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.4685368, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.36411405, shape=(), dtype=float32)\n",
      "Training loss is: 0.36411405\n",
      "loss value: tf.Tensor(0.024194276, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.45997965, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.35825622, shape=(), dtype=float32)\n",
      "Training loss is: 0.35825622\n",
      "loss value: tf.Tensor(0.023224797, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.45124695, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.352829, shape=(), dtype=float32)\n",
      "Training loss is: 0.352829\n",
      "loss value: tf.Tensor(0.022319412, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.44244453, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.34766805, shape=(), dtype=float32)\n",
      "Training loss is: 0.34766805\n",
      "loss value: tf.Tensor(0.02148241, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.4338857, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.34246868, shape=(), dtype=float32)\n",
      "Training loss is: 0.34246868\n",
      "loss value: tf.Tensor(0.020719877, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.4256537, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.33724838, shape=(), dtype=float32)\n",
      "Training loss is: 0.33724838\n",
      "loss value: tf.Tensor(0.019996207, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.41755715, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.33222365, shape=(), dtype=float32)\n",
      "Training loss is: 0.33222365\n",
      "loss value: tf.Tensor(0.019264005, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.40965542, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.32718807, shape=(), dtype=float32)\n",
      "Training loss is: 0.32718807\n",
      "loss value: tf.Tensor(0.018539708, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.4020804, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.32211, shape=(), dtype=float32)\n",
      "Training loss is: 0.32211\n",
      "loss value: tf.Tensor(0.017834116, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.39488816, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.3168234, shape=(), dtype=float32)\n",
      "Training loss is: 0.3168234\n",
      "loss value: tf.Tensor(0.01716674, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.38818797, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.31128705, shape=(), dtype=float32)\n",
      "Training loss is: 0.31128705\n",
      "loss value: tf.Tensor(0.01653637, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.38178924, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.3058101, shape=(), dtype=float32)\n",
      "Training loss is: 0.3058101\n",
      "loss value: tf.Tensor(0.01592188, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.3752497, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.3007733, shape=(), dtype=float32)\n",
      "Training loss is: 0.3007733\n",
      "loss value: tf.Tensor(0.015318449, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.36859038, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.2960307, shape=(), dtype=float32)\n",
      "Training loss is: 0.2960307\n",
      "loss value: tf.Tensor(0.014737333, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.36215156, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.29116744, shape=(), dtype=float32)\n",
      "Training loss is: 0.29116744\n",
      "loss value: tf.Tensor(0.014201658, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.35609135, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.28614837, shape=(), dtype=float32)\n",
      "Training loss is: 0.28614837\n",
      "loss value: tf.Tensor(0.01370665, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.35032147, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.28107587, shape=(), dtype=float32)\n",
      "Training loss is: 0.28107587\n",
      "loss value: tf.Tensor(0.013238826, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.34451947, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.27636176, shape=(), dtype=float32)\n",
      "Training loss is: 0.27636176\n",
      "loss value: tf.Tensor(0.012794938, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.33865973, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.271877, shape=(), dtype=float32)\n",
      "Training loss is: 0.271877\n",
      "loss value: tf.Tensor(0.012380567, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.33292127, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.26749718, shape=(), dtype=float32)\n",
      "Training loss is: 0.26749718\n",
      "loss value: tf.Tensor(0.011985197, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.32729185, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.26318243, shape=(), dtype=float32)\n",
      "Training loss is: 0.26318243\n",
      "loss value: tf.Tensor(0.011609564, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.32192597, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.25881806, shape=(), dtype=float32)\n",
      "Training loss is: 0.25881806\n",
      "loss value: tf.Tensor(0.011258479, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.31669432, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.25463107, shape=(), dtype=float32)\n",
      "Training loss is: 0.25463107\n",
      "loss value: tf.Tensor(0.010929342, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.3115883, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.25060567, shape=(), dtype=float32)\n",
      "Training loss is: 0.25060567\n",
      "loss value: tf.Tensor(0.010609848, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.3066082, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.2466855, shape=(), dtype=float32)\n",
      "Training loss is: 0.2466855\n",
      "loss value: tf.Tensor(0.010299098, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.3017993, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.24283785, shape=(), dtype=float32)\n",
      "Training loss is: 0.24283785\n",
      "loss value: tf.Tensor(0.010007838, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.2972558, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.23897806, shape=(), dtype=float32)\n",
      "Training loss is: 0.23897806\n",
      "loss value: tf.Tensor(0.009735901, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.2928047, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.23534569, shape=(), dtype=float32)\n",
      "Training loss is: 0.23534569\n",
      "loss value: tf.Tensor(0.009472322, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.28821516, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.23211518, shape=(), dtype=float32)\n",
      "Training loss is: 0.23211518\n",
      "loss value: tf.Tensor(0.009214064, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.28363913, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.22861394, shape=(), dtype=float32)\n",
      "Training loss is: 0.22861394\n",
      "loss value: tf.Tensor(0.008966306, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.27958918, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.22300452, shape=(), dtype=float32)\n",
      "Training loss is: 0.22300452\n",
      "loss value: tf.Tensor(0.008732854, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.27681485, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.2138563, shape=(), dtype=float32)\n",
      "Training loss is: 0.2138563\n",
      "loss value: tf.Tensor(0.008502725, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.27548036, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.20520492, shape=(), dtype=float32)\n",
      "Training loss is: 0.20520492\n",
      "loss value: tf.Tensor(0.008263551, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.27213153, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.20166036, shape=(), dtype=float32)\n",
      "Training loss is: 0.20166036\n",
      "loss value: tf.Tensor(0.008014651, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.2652132, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.20178193, shape=(), dtype=float32)\n",
      "Training loss is: 0.20178193\n",
      "loss value: tf.Tensor(0.0077763777, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.25739115, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.20234448, shape=(), dtype=float32)\n",
      "Training loss is: 0.20234448\n",
      "loss value: tf.Tensor(0.0075696446, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.2512999, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.20097212, shape=(), dtype=float32)\n",
      "Training loss is: 0.20097212\n",
      "loss value: tf.Tensor(0.0074009686, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.24791193, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.19712475, shape=(), dtype=float32)\n",
      "Training loss is: 0.19712475\n",
      "loss value: tf.Tensor(0.007262401, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.24649183, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.19202752, shape=(), dtype=float32)\n",
      "Training loss is: 0.19202752\n",
      "loss value: tf.Tensor(0.0071357125, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.24538106, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.18743019, shape=(), dtype=float32)\n",
      "Training loss is: 0.18743019\n",
      "loss value: tf.Tensor(0.0070034163, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.24319792, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.18438435, shape=(), dtype=float32)\n",
      "Training loss is: 0.18438435\n",
      "loss value: tf.Tensor(0.0068592513, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.23964453, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.18278489, shape=(), dtype=float32)\n",
      "Training loss is: 0.18278489\n",
      "loss value: tf.Tensor(0.0067073163, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.23542956, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.18172371, shape=(), dtype=float32)\n",
      "Training loss is: 0.18172371\n",
      "loss value: tf.Tensor(0.006557388, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.23155242, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.18026742, shape=(), dtype=float32)\n",
      "Training loss is: 0.18026742\n",
      "loss value: tf.Tensor(0.00641526, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.22856237, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.17803675, shape=(), dtype=float32)\n",
      "Training loss is: 0.17803675\n",
      "loss value: tf.Tensor(0.0062815673, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.22643562, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.17521304, shape=(), dtype=float32)\n",
      "Training loss is: 0.17521304\n",
      "loss value: tf.Tensor(0.0061532636, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.22466503, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.17239824, shape=(), dtype=float32)\n",
      "Training loss is: 0.17239824\n",
      "loss value: tf.Tensor(0.0060258107, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.2227217, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.17002964, shape=(), dtype=float32)\n",
      "Training loss is: 0.17002964\n",
      "loss value: tf.Tensor(0.005897258, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.22041577, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.16815974, shape=(), dtype=float32)\n",
      "Training loss is: 0.16815974\n",
      "loss value: tf.Tensor(0.005768014, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.21782394, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.16664271, shape=(), dtype=float32)\n",
      "Training loss is: 0.16664271\n",
      "loss value: tf.Tensor(0.0056413715, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.21527499, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.16510834, shape=(), dtype=float32)\n",
      "Training loss is: 0.16510834\n",
      "loss value: tf.Tensor(0.0055208886, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.2131046, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.16322145, shape=(), dtype=float32)\n",
      "Training loss is: 0.16322145\n",
      "loss value: tf.Tensor(0.0054045455, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.21097408, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.16150849, shape=(), dtype=float32)\n",
      "Training loss is: 0.16150849\n",
      "loss value: tf.Tensor(0.005292773, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.20929219, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.15890716, shape=(), dtype=float32)\n",
      "Training loss is: 0.15890716\n",
      "loss value: tf.Tensor(0.00518541, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.20977549, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.15355684, shape=(), dtype=float32)\n",
      "Training loss is: 0.15355684\n",
      "loss value: tf.Tensor(0.0050772387, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.21103486, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.14510025, shape=(), dtype=float32)\n",
      "Training loss is: 0.14510025\n",
      "loss value: tf.Tensor(0.004958299, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.2099929, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.1427442, shape=(), dtype=float32)\n",
      "Training loss is: 0.1427442\n",
      "loss value: tf.Tensor(0.00482425, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.20407988, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.14539939, shape=(), dtype=float32)\n",
      "Training loss is: 0.14539939\n",
      "loss value: tf.Tensor(0.0046910373, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.19687943, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.14850588, shape=(), dtype=float32)\n",
      "Training loss is: 0.14850588\n",
      "loss value: tf.Tensor(0.004577356, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.1923435, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.14845487, shape=(), dtype=float32)\n",
      "Training loss is: 0.14845487\n",
      "loss value: tf.Tensor(0.0044906125, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.19154833, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.14493746, shape=(), dtype=float32)\n",
      "Training loss is: 0.14493746\n",
      "loss value: tf.Tensor(0.0044222213, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.19282389, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.14035377, shape=(), dtype=float32)\n",
      "Training loss is: 0.14035377\n",
      "loss value: tf.Tensor(0.004354256, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.19357143, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.13718143, shape=(), dtype=float32)\n",
      "Training loss is: 0.13718143\n",
      "loss value: tf.Tensor(0.004275203, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.19231705, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.136199, shape=(), dtype=float32)\n",
      "Training loss is: 0.136199\n",
      "loss value: tf.Tensor(0.0041833688, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.18944067, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.13654304, shape=(), dtype=float32)\n",
      "Training loss is: 0.13654304\n",
      "loss value: tf.Tensor(0.004085005, shape=(), dtype=float32)\n",
      "loss value: tf.Tensor(0.18639559, shape=(), dtype=float32)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/kuzaowuwei/Desktop/2022//3/code/DecisionModel.ipynb Cell 8'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kuzaowuwei/Desktop/2022%E7%BE%8E%E8%B5%9B/%E8%B5%9B%E4%B8%AD%E6%95%B0%E6%8D%AE/3%E6%8C%87%E6%A0%87%E4%BD%93%E7%B3%BB/code/DecisionModel.ipynb#ch0000006?line=15'>16</a>\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mloss value:\u001b[39m\u001b[39m'\u001b[39m,loss_value)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kuzaowuwei/Desktop/2022%E7%BE%8E%E8%B5%9B/%E8%B5%9B%E4%B8%AD%E6%95%B0%E6%8D%AE/3%E6%8C%87%E6%A0%87%E4%BD%93%E7%B3%BB/code/DecisionModel.ipynb#ch0000006?line=16'>17</a>\u001b[0m         grads\u001b[39m=\u001b[39mtape\u001b[39m.\u001b[39mgradient(loss_value,model\u001b[39m.\u001b[39mtrainable_variables)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/kuzaowuwei/Desktop/2022%E7%BE%8E%E8%B5%9B/%E8%B5%9B%E4%B8%AD%E6%95%B0%E6%8D%AE/3%E6%8C%87%E6%A0%87%E4%BD%93%E7%B3%BB/code/DecisionModel.ipynb#ch0000006?line=17'>18</a>\u001b[0m         opt\u001b[39m.\u001b[39;49mapply_gradients(\u001b[39mzip\u001b[39;49m(grads,model\u001b[39m.\u001b[39;49mtrainable_variables))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kuzaowuwei/Desktop/2022%E7%BE%8E%E8%B5%9B/%E8%B5%9B%E4%B8%AD%E6%95%B0%E6%8D%AE/3%E6%8C%87%E6%A0%87%E4%BD%93%E7%B3%BB/code/DecisionModel.ipynb#ch0000006?line=18'>19</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mTraining loss is:\u001b[39m\u001b[39m'\u001b[39m,loss_value\u001b[39m.\u001b[39mnumpy() )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py4tf/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py:671\u001b[0m, in \u001b[0;36mOptimizerV2.apply_gradients\u001b[0;34m(self, grads_and_vars, name, experimental_aggregate_gradients)\u001b[0m\n\u001b[1;32m    <a href='file:///~/opt/anaconda3/envs/py4tf/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py?line=667'>668</a>\u001b[0m   grads_and_vars \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_aggregate_gradients(grads_and_vars)\n\u001b[1;32m    <a href='file:///~/opt/anaconda3/envs/py4tf/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py?line=668'>669</a>\u001b[0m grads_and_vars \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_transform_gradients(grads_and_vars)\n\u001b[0;32m--> <a href='file:///~/opt/anaconda3/envs/py4tf/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py?line=670'>671</a>\u001b[0m \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49m__internal__\u001b[39m.\u001b[39;49mdistribute\u001b[39m.\u001b[39;49minterim\u001b[39m.\u001b[39;49mmaybe_merge_call(\n\u001b[1;32m    <a href='file:///~/opt/anaconda3/envs/py4tf/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py?line=671'>672</a>\u001b[0m     functools\u001b[39m.\u001b[39;49mpartial(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_distributed_apply, apply_state\u001b[39m=\u001b[39;49mapply_state),\n\u001b[1;32m    <a href='file:///~/opt/anaconda3/envs/py4tf/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py?line=672'>673</a>\u001b[0m     strategy,\n\u001b[1;32m    <a href='file:///~/opt/anaconda3/envs/py4tf/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py?line=673'>674</a>\u001b[0m     grads_and_vars,\n\u001b[1;32m    <a href='file:///~/opt/anaconda3/envs/py4tf/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py?line=674'>675</a>\u001b[0m     name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py4tf/lib/python3.8/site-packages/tensorflow/python/distribute/merge_call_interim.py:51\u001b[0m, in \u001b[0;36mmaybe_merge_call\u001b[0;34m(fn, strategy, *args, **kwargs)\u001b[0m\n\u001b[1;32m     <a href='file:///~/opt/anaconda3/envs/py4tf/lib/python3.8/site-packages/tensorflow/python/distribute/merge_call_interim.py?line=30'>31</a>\u001b[0m \u001b[39m\"\"\"Maybe invoke `fn` via `merge_call` which may or may not be fulfilled.\u001b[39;00m\n\u001b[1;32m     <a href='file:///~/opt/anaconda3/envs/py4tf/lib/python3.8/site-packages/tensorflow/python/distribute/merge_call_interim.py?line=31'>32</a>\u001b[0m \n\u001b[1;32m     <a href='file:///~/opt/anaconda3/envs/py4tf/lib/python3.8/site-packages/tensorflow/python/distribute/merge_call_interim.py?line=32'>33</a>\u001b[0m \u001b[39mThe caller of this utility function requests to invoke `fn` via `merge_call`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='file:///~/opt/anaconda3/envs/py4tf/lib/python3.8/site-packages/tensorflow/python/distribute/merge_call_interim.py?line=47'>48</a>\u001b[0m \u001b[39m  The return value of the `fn` call.\u001b[39;00m\n\u001b[1;32m     <a href='file:///~/opt/anaconda3/envs/py4tf/lib/python3.8/site-packages/tensorflow/python/distribute/merge_call_interim.py?line=48'>49</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     <a href='file:///~/opt/anaconda3/envs/py4tf/lib/python3.8/site-packages/tensorflow/python/distribute/merge_call_interim.py?line=49'>50</a>\u001b[0m \u001b[39mif\u001b[39;00m strategy_supports_no_merge_call():\n\u001b[0;32m---> <a href='file:///~/opt/anaconda3/envs/py4tf/lib/python3.8/site-packages/tensorflow/python/distribute/merge_call_interim.py?line=50'>51</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(strategy, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     <a href='file:///~/opt/anaconda3/envs/py4tf/lib/python3.8/site-packages/tensorflow/python/distribute/merge_call_interim.py?line=51'>52</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='file:///~/opt/anaconda3/envs/py4tf/lib/python3.8/site-packages/tensorflow/python/distribute/merge_call_interim.py?line=52'>53</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m distribution_strategy_context\u001b[39m.\u001b[39mget_replica_context()\u001b[39m.\u001b[39mmerge_call(\n\u001b[1;32m     <a href='file:///~/opt/anaconda3/envs/py4tf/lib/python3.8/site-packages/tensorflow/python/distribute/merge_call_interim.py?line=53'>54</a>\u001b[0m       fn, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py4tf/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py:716\u001b[0m, in \u001b[0;36mOptimizerV2._distributed_apply\u001b[0;34m(self, distribution, grads_and_vars, apply_state, name)\u001b[0m\n\u001b[1;32m    <a href='file:///~/opt/anaconda3/envs/py4tf/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py?line=711'>712</a>\u001b[0m \u001b[39mwith\u001b[39;00m distribution\u001b[39m.\u001b[39mextended\u001b[39m.\u001b[39mcolocate_vars_with(var):\n\u001b[1;32m    <a href='file:///~/opt/anaconda3/envs/py4tf/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py?line=712'>713</a>\u001b[0m   \u001b[39mwith\u001b[39;00m name_scope_only_in_function_or_graph(\n\u001b[1;32m    <a href='file:///~/opt/anaconda3/envs/py4tf/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py?line=713'>714</a>\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mupdate\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m eagerly_outside_functions \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mupdate_\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m\n\u001b[1;32m    <a href='file:///~/opt/anaconda3/envs/py4tf/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py?line=714'>715</a>\u001b[0m       var\u001b[39m.\u001b[39mop\u001b[39m.\u001b[39mname):\n\u001b[0;32m--> <a href='file:///~/opt/anaconda3/envs/py4tf/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py?line=715'>716</a>\u001b[0m     update_op \u001b[39m=\u001b[39m distribution\u001b[39m.\u001b[39;49mextended\u001b[39m.\u001b[39;49mupdate(\n\u001b[1;32m    <a href='file:///~/opt/anaconda3/envs/py4tf/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py?line=716'>717</a>\u001b[0m         var, apply_grad_to_update_var, args\u001b[39m=\u001b[39;49m(grad,), group\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    <a href='file:///~/opt/anaconda3/envs/py4tf/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py?line=717'>718</a>\u001b[0m     \u001b[39mif\u001b[39;00m tf\u001b[39m.\u001b[39mdistribute\u001b[39m.\u001b[39min_cross_replica_context():\n\u001b[1;32m    <a href='file:///~/opt/anaconda3/envs/py4tf/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py?line=718'>719</a>\u001b[0m       \u001b[39m# In cross-replica context, extended.update returns a list of\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/opt/anaconda3/envs/py4tf/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py?line=719'>720</a>\u001b[0m       \u001b[39m# update ops from all replicas (group=False).\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/opt/anaconda3/envs/py4tf/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py?line=720'>721</a>\u001b[0m       update_ops\u001b[39m.\u001b[39mextend(update_op)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py4tf/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2630\u001b[0m, in \u001b[0;36mStrategyExtendedV2.update\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   <a href='file:///~/opt/anaconda3/envs/py4tf/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py?line=2626'>2627</a>\u001b[0m   fn \u001b[39m=\u001b[39m autograph\u001b[39m.\u001b[39mtf_convert(\n\u001b[1;32m   <a href='file:///~/opt/anaconda3/envs/py4tf/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py?line=2627'>2628</a>\u001b[0m       fn, autograph_ctx\u001b[39m.\u001b[39mcontrol_status_ctx(), convert_by_default\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m   <a href='file:///~/opt/anaconda3/envs/py4tf/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py?line=2628'>2629</a>\u001b[0m   \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_container_strategy()\u001b[39m.\u001b[39mscope():\n\u001b[0;32m-> <a href='file:///~/opt/anaconda3/envs/py4tf/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py?line=2629'>2630</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update(var, fn, args, kwargs, group)\n\u001b[1;32m   <a href='file:///~/opt/anaconda3/envs/py4tf/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py?line=2630'>2631</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   <a href='file:///~/opt/anaconda3/envs/py4tf/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py?line=2631'>2632</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_replica_ctx_update(\n\u001b[1;32m   <a href='file:///~/opt/anaconda3/envs/py4tf/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py?line=2632'>2633</a>\u001b[0m       var, fn, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs, group\u001b[39m=\u001b[39mgroup)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py4tf/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:3703\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._update\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   <a href='file:///~/opt/anaconda3/envs/py4tf/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py?line=3699'>3700</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_update\u001b[39m(\u001b[39mself\u001b[39m, var, fn, args, kwargs, group):\n\u001b[1;32m   <a href='file:///~/opt/anaconda3/envs/py4tf/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py?line=3700'>3701</a>\u001b[0m   \u001b[39m# The implementations of _update() and _update_non_slot() are identical\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/opt/anaconda3/envs/py4tf/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py?line=3701'>3702</a>\u001b[0m   \u001b[39m# except _update() passes `var` as the first argument to `fn()`.\u001b[39;00m\n\u001b[0;32m-> <a href='file:///~/opt/anaconda3/envs/py4tf/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py?line=3702'>3703</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_non_slot(var, fn, (var,) \u001b[39m+\u001b[39;49m \u001b[39mtuple\u001b[39;49m(args), kwargs, group)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py4tf/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:3708\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._update_non_slot\u001b[0;34m(self, colocate_with, fn, args, kwargs, should_group)\u001b[0m\n\u001b[1;32m   <a href='file:///~/opt/anaconda3/envs/py4tf/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py?line=3704'>3705</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_update_non_slot\u001b[39m(\u001b[39mself\u001b[39m, colocate_with, fn, args, kwargs, should_group):\n\u001b[1;32m   <a href='file:///~/opt/anaconda3/envs/py4tf/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py?line=3705'>3706</a>\u001b[0m   \u001b[39m# TODO(josh11b): Figure out what we should be passing to UpdateContext()\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/opt/anaconda3/envs/py4tf/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py?line=3706'>3707</a>\u001b[0m   \u001b[39m# once that value is used for something.\u001b[39;00m\n\u001b[0;32m-> <a href='file:///~/opt/anaconda3/envs/py4tf/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py?line=3707'>3708</a>\u001b[0m   \u001b[39mwith\u001b[39;00m UpdateContext(colocate_with):\n\u001b[1;32m   <a href='file:///~/opt/anaconda3/envs/py4tf/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py?line=3708'>3709</a>\u001b[0m     result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   <a href='file:///~/opt/anaconda3/envs/py4tf/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py?line=3709'>3710</a>\u001b[0m     \u001b[39mif\u001b[39;00m should_group:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py4tf/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:252\u001b[0m, in \u001b[0;36mUpdateContext.__init__\u001b[0;34m(self, replica_id)\u001b[0m\n\u001b[1;32m    <a href='file:///~/opt/anaconda3/envs/py4tf/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py?line=247'>248</a>\u001b[0m \u001b[39m\"\"\"Context manager when you are in `update()` or `update_non_slot()`.\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/opt/anaconda3/envs/py4tf/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py?line=249'>250</a>\u001b[0m \u001b[39m__slots__\u001b[39m \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39m_replica_id\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m_old_replica_id\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m--> <a href='file:///~/opt/anaconda3/envs/py4tf/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py?line=251'>252</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, replica_id):\n\u001b[1;32m    <a href='file:///~/opt/anaconda3/envs/py4tf/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py?line=252'>253</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_replica_id \u001b[39m=\u001b[39m replica_id\n\u001b[1;32m    <a href='file:///~/opt/anaconda3/envs/py4tf/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py?line=253'>254</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_old_replica_id \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model=tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Dense(64,activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(128,activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(32,activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(3,activation='softmax'))\n",
    "opt=tf.optimizers.Adam(1e-3)\n",
    "for epoch in range(1000):\n",
    "    for _data,lable in zip(iris_data,iris_target):\n",
    "        with tf.GradientTape() as tape:\n",
    "            logits=model(_data)\n",
    "            # print(lable.shape, lable)\n",
    "            # loss value needs to be modified\n",
    "\n",
    "            loss_value=tf.reduce_mean(tf.keras.losses.categorical_crossentropy(\n",
    "                    y_true=lable,y_pred=logits))\n",
    "            print('loss value:',loss_value)\n",
    "            grads=tape.gradient(loss_value,model.trainable_variables)\n",
    "            opt.apply_gradients(zip(grads,model.trainable_variables))\n",
    "    print('Training loss is:',loss_value.numpy() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss value: tf.Tensor(-21.860655, shape=(), dtype=float32)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No gradients provided for any variable: (['dense_168/kernel:0', 'dense_168/bias:0', 'dense_169/kernel:0', 'dense_169/bias:0', 'dense_170/kernel:0', 'dense_170/bias:0', 'dense_171/kernel:0', 'dense_171/bias:0'],). Provided `grads_and_vars` is ((None, <tf.Variable 'dense_168/kernel:0' shape=(18, 64) dtype=float32, numpy=\narray([[ 0.19742948, -0.10431659,  0.26767385, ...,  0.003012  ,\n         0.19838628, -0.05312939],\n       [ 0.15130797, -0.04367582, -0.13900506, ..., -0.03985104,\n         0.18629485, -0.09898938],\n       [ 0.06746188, -0.04878646,  0.09262177, ..., -0.16498837,\n        -0.07625727, -0.21430695],\n       ...,\n       [-0.06377374, -0.23086095, -0.14188395, ...,  0.11375564,\n        -0.04438969, -0.2555705 ],\n       [ 0.10887769, -0.03555462, -0.20593688, ...,  0.09438753,\n        -0.06359993, -0.10652468],\n       [ 0.18952459,  0.11936933,  0.01040462, ...,  0.20864537,\n         0.09110931, -0.12907104]], dtype=float32)>), (None, <tf.Variable 'dense_168/bias:0' shape=(64,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>), (None, <tf.Variable 'dense_169/kernel:0' shape=(64, 128) dtype=float32, numpy=\narray([[-1.46444276e-01, -3.34895849e-02, -1.35298923e-01, ...,\n         7.51799345e-03, -1.56808659e-01, -9.74798426e-02],\n       [-3.60042751e-02, -1.06608510e-01,  6.48951083e-02, ...,\n         2.74836272e-02, -8.31086561e-02, -1.09950885e-01],\n       [-2.29530483e-02,  7.76250511e-02, -8.90766010e-02, ...,\n        -4.28326130e-02, -7.51021877e-02, -3.38479280e-02],\n       ...,\n       [-9.11356434e-02,  9.69639271e-02,  1.10460892e-01, ...,\n        -1.60995856e-01, -1.52339041e-03,  5.36310226e-02],\n       [-1.00275695e-01,  6.58039600e-02, -1.79283768e-02, ...,\n        -1.26207724e-01, -1.40707284e-01, -1.62662551e-01],\n       [ 1.02944076e-02,  5.56907356e-02,  1.27702951e-04, ...,\n        -1.70709267e-01, -1.55449539e-01, -1.57297805e-01]], dtype=float32)>), (None, <tf.Variable 'dense_169/bias:0' shape=(128,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>), (None, <tf.Variable 'dense_170/kernel:0' shape=(128, 32) dtype=float32, numpy=\narray([[-7.7545837e-02,  8.7927490e-02, -1.6217847e-01, ...,\n        -8.2276911e-03, -4.7364712e-02, -1.9313799e-01],\n       [-8.2969375e-02,  1.6132891e-01, -1.6293742e-01, ...,\n         1.5377656e-02,  1.0528779e-01,  1.3304105e-01],\n       [-1.3354075e-01, -1.8542416e-01, -1.4812668e-01, ...,\n        -8.3281808e-02,  1.2046054e-02, -1.0734460e-01],\n       ...,\n       [ 2.1016523e-02,  1.4211819e-02, -1.2673438e-04, ...,\n         1.3758963e-01, -4.7146827e-02, -3.5619959e-02],\n       [-6.7070842e-02, -1.4825407e-01,  1.9334108e-02, ...,\n        -1.5477800e-01, -1.4473243e-01, -5.6041926e-03],\n       [-1.7265388e-01, -5.8268011e-02,  8.8322967e-02, ...,\n         9.1381699e-02, -1.2689695e-01, -1.3943017e-04]], dtype=float32)>), (None, <tf.Variable 'dense_170/bias:0' shape=(32,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n      dtype=float32)>), (None, <tf.Variable 'dense_171/kernel:0' shape=(32, 3) dtype=float32, numpy=\narray([[-0.14802611, -0.17663312,  0.24846485],\n       [ 0.14170894,  0.20962772, -0.2235752 ],\n       [ 0.25409856, -0.142681  , -0.35423818],\n       [-0.35873434, -0.22375527,  0.30103424],\n       [ 0.03979909, -0.06450826, -0.08402258],\n       [-0.24260809,  0.31510583,  0.25095245],\n       [-0.26781625,  0.34018192,  0.04174289],\n       [-0.09700334,  0.07669389, -0.356626  ],\n       [-0.1723568 , -0.18671633, -0.40805772],\n       [ 0.30375198, -0.09862858, -0.19336556],\n       [ 0.37528083, -0.03854156, -0.1912805 ],\n       [-0.31775108,  0.20650467, -0.33391097],\n       [ 0.27144143,  0.4087684 , -0.1812588 ],\n       [ 0.2466388 ,  0.34021053,  0.09756497],\n       [ 0.41183266,  0.2655494 , -0.15584153],\n       [-0.13322464, -0.11051285,  0.13289544],\n       [-0.33438343, -0.12576783,  0.40554455],\n       [ 0.37565777, -0.38698402,  0.24261996],\n       [-0.39886266,  0.00347713,  0.04457262],\n       [-0.4079673 , -0.17909843, -0.28399962],\n       [-0.0095993 , -0.1248005 , -0.09170592],\n       [-0.19293664,  0.17376962,  0.30902448],\n       [ 0.12625852, -0.22401735,  0.01145673],\n       [-0.34048152,  0.30327544, -0.11391011],\n       [-0.25769645, -0.03775835, -0.1359928 ],\n       [ 0.29896125, -0.25628224, -0.38777888],\n       [-0.2455024 ,  0.13248578, -0.10831308],\n       [-0.3034248 ,  0.37395015,  0.04530638],\n       [-0.2807859 ,  0.40852126, -0.06248668],\n       [ 0.4078144 ,  0.16696164,  0.089964  ],\n       [ 0.09533539, -0.20072375,  0.20853624],\n       [-0.39300898, -0.2615564 , -0.18440326]], dtype=float32)>), (None, <tf.Variable 'dense_171/bias:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>)).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/kuzaowuwei/Desktop/2022//3/code/DecisionModel.ipynb Cell 9'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kuzaowuwei/Desktop/2022%E7%BE%8E%E8%B5%9B/%E8%B5%9B%E4%B8%AD%E6%95%B0%E6%8D%AE/3%E6%8C%87%E6%A0%87%E4%BD%93%E7%B3%BB/code/DecisionModel.ipynb#ch0000008?line=81'>82</a>\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mloss value:\u001b[39m\u001b[39m'\u001b[39m, loss_value)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kuzaowuwei/Desktop/2022%E7%BE%8E%E8%B5%9B/%E8%B5%9B%E4%B8%AD%E6%95%B0%E6%8D%AE/3%E6%8C%87%E6%A0%87%E4%BD%93%E7%B3%BB/code/DecisionModel.ipynb#ch0000008?line=83'>84</a>\u001b[0m         grads\u001b[39m=\u001b[39mtape\u001b[39m.\u001b[39mgradient(loss_value,model\u001b[39m.\u001b[39mtrainable_variables)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/kuzaowuwei/Desktop/2022%E7%BE%8E%E8%B5%9B/%E8%B5%9B%E4%B8%AD%E6%95%B0%E6%8D%AE/3%E6%8C%87%E6%A0%87%E4%BD%93%E7%B3%BB/code/DecisionModel.ipynb#ch0000008?line=84'>85</a>\u001b[0m         opt\u001b[39m.\u001b[39;49mapply_gradients(\u001b[39mzip\u001b[39;49m(grads,model\u001b[39m.\u001b[39;49mtrainable_variables))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kuzaowuwei/Desktop/2022%E7%BE%8E%E8%B5%9B/%E8%B5%9B%E4%B8%AD%E6%95%B0%E6%8D%AE/3%E6%8C%87%E6%A0%87%E4%BD%93%E7%B3%BB/code/DecisionModel.ipynb#ch0000008?line=85'>86</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mTraining loss is:\u001b[39m\u001b[39m'\u001b[39m,loss_value\u001b[39m.\u001b[39mnumpy() )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py4tf/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py:633\u001b[0m, in \u001b[0;36mOptimizerV2.apply_gradients\u001b[0;34m(self, grads_and_vars, name, experimental_aggregate_gradients)\u001b[0m\n\u001b[1;32m    <a href='file:///~/opt/anaconda3/envs/py4tf/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py?line=591'>592</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_gradients\u001b[39m(\u001b[39mself\u001b[39m,\n\u001b[1;32m    <a href='file:///~/opt/anaconda3/envs/py4tf/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py?line=592'>593</a>\u001b[0m                     grads_and_vars,\n\u001b[1;32m    <a href='file:///~/opt/anaconda3/envs/py4tf/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py?line=593'>594</a>\u001b[0m                     name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    <a href='file:///~/opt/anaconda3/envs/py4tf/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py?line=594'>595</a>\u001b[0m                     experimental_aggregate_gradients\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m    <a href='file:///~/opt/anaconda3/envs/py4tf/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py?line=595'>596</a>\u001b[0m   \u001b[39m\"\"\"Apply gradients to variables.\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/opt/anaconda3/envs/py4tf/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py?line=596'>597</a>\u001b[0m \n\u001b[1;32m    <a href='file:///~/opt/anaconda3/envs/py4tf/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py?line=597'>598</a>\u001b[0m \u001b[39m  This is the second part of `minimize()`. It returns an `Operation` that\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///~/opt/anaconda3/envs/py4tf/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py?line=630'>631</a>\u001b[0m \u001b[39m    RuntimeError: If called in a cross-replica context.\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/opt/anaconda3/envs/py4tf/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py?line=631'>632</a>\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> <a href='file:///~/opt/anaconda3/envs/py4tf/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py?line=632'>633</a>\u001b[0m   grads_and_vars \u001b[39m=\u001b[39m optimizer_utils\u001b[39m.\u001b[39;49mfilter_empty_gradients(grads_and_vars)\n\u001b[1;32m    <a href='file:///~/opt/anaconda3/envs/py4tf/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py?line=633'>634</a>\u001b[0m   var_list \u001b[39m=\u001b[39m [v \u001b[39mfor\u001b[39;00m (_, v) \u001b[39min\u001b[39;00m grads_and_vars]\n\u001b[1;32m    <a href='file:///~/opt/anaconda3/envs/py4tf/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py?line=635'>636</a>\u001b[0m   \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mname_scope(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_name):\n\u001b[1;32m    <a href='file:///~/opt/anaconda3/envs/py4tf/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py?line=636'>637</a>\u001b[0m     \u001b[39m# Create iteration if necessary.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py4tf/lib/python3.8/site-packages/keras/optimizer_v2/utils.py:73\u001b[0m, in \u001b[0;36mfilter_empty_gradients\u001b[0;34m(grads_and_vars)\u001b[0m\n\u001b[1;32m     <a href='file:///~/opt/anaconda3/envs/py4tf/lib/python3.8/site-packages/keras/optimizer_v2/utils.py?line=70'>71</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m filtered:\n\u001b[1;32m     <a href='file:///~/opt/anaconda3/envs/py4tf/lib/python3.8/site-packages/keras/optimizer_v2/utils.py?line=71'>72</a>\u001b[0m   variable \u001b[39m=\u001b[39m ([v\u001b[39m.\u001b[39mname \u001b[39mfor\u001b[39;00m _, v \u001b[39min\u001b[39;00m grads_and_vars],)\n\u001b[0;32m---> <a href='file:///~/opt/anaconda3/envs/py4tf/lib/python3.8/site-packages/keras/optimizer_v2/utils.py?line=72'>73</a>\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNo gradients provided for any variable: \u001b[39m\u001b[39m{\u001b[39;00mvariable\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='file:///~/opt/anaconda3/envs/py4tf/lib/python3.8/site-packages/keras/optimizer_v2/utils.py?line=73'>74</a>\u001b[0m                    \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mProvided `grads_and_vars` is \u001b[39m\u001b[39m{\u001b[39;00mgrads_and_vars\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='file:///~/opt/anaconda3/envs/py4tf/lib/python3.8/site-packages/keras/optimizer_v2/utils.py?line=74'>75</a>\u001b[0m \u001b[39mif\u001b[39;00m vars_with_empty_grads:\n\u001b[1;32m     <a href='file:///~/opt/anaconda3/envs/py4tf/lib/python3.8/site-packages/keras/optimizer_v2/utils.py?line=75'>76</a>\u001b[0m   logging\u001b[39m.\u001b[39mwarning(\n\u001b[1;32m     <a href='file:///~/opt/anaconda3/envs/py4tf/lib/python3.8/site-packages/keras/optimizer_v2/utils.py?line=76'>77</a>\u001b[0m       (\u001b[39m\"\u001b[39m\u001b[39mGradients do not exist for variables \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m when minimizing the loss. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='file:///~/opt/anaconda3/envs/py4tf/lib/python3.8/site-packages/keras/optimizer_v2/utils.py?line=77'>78</a>\u001b[0m        \u001b[39m\"\u001b[39m\u001b[39mIf you\u001b[39m\u001b[39m'\u001b[39m\u001b[39mre using `model.compile()`, did you forget to provide a `loss`\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='file:///~/opt/anaconda3/envs/py4tf/lib/python3.8/site-packages/keras/optimizer_v2/utils.py?line=78'>79</a>\u001b[0m        \u001b[39m\"\u001b[39m\u001b[39margument?\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m     <a href='file:///~/opt/anaconda3/envs/py4tf/lib/python3.8/site-packages/keras/optimizer_v2/utils.py?line=79'>80</a>\u001b[0m       ([v\u001b[39m.\u001b[39mname \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m vars_with_empty_grads]))\n",
      "\u001b[0;31mValueError\u001b[0m: No gradients provided for any variable: (['dense_168/kernel:0', 'dense_168/bias:0', 'dense_169/kernel:0', 'dense_169/bias:0', 'dense_170/kernel:0', 'dense_170/bias:0', 'dense_171/kernel:0', 'dense_171/bias:0'],). Provided `grads_and_vars` is ((None, <tf.Variable 'dense_168/kernel:0' shape=(18, 64) dtype=float32, numpy=\narray([[ 0.19742948, -0.10431659,  0.26767385, ...,  0.003012  ,\n         0.19838628, -0.05312939],\n       [ 0.15130797, -0.04367582, -0.13900506, ..., -0.03985104,\n         0.18629485, -0.09898938],\n       [ 0.06746188, -0.04878646,  0.09262177, ..., -0.16498837,\n        -0.07625727, -0.21430695],\n       ...,\n       [-0.06377374, -0.23086095, -0.14188395, ...,  0.11375564,\n        -0.04438969, -0.2555705 ],\n       [ 0.10887769, -0.03555462, -0.20593688, ...,  0.09438753,\n        -0.06359993, -0.10652468],\n       [ 0.18952459,  0.11936933,  0.01040462, ...,  0.20864537,\n         0.09110931, -0.12907104]], dtype=float32)>), (None, <tf.Variable 'dense_168/bias:0' shape=(64,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>), (None, <tf.Variable 'dense_169/kernel:0' shape=(64, 128) dtype=float32, numpy=\narray([[-1.46444276e-01, -3.34895849e-02, -1.35298923e-01, ...,\n         7.51799345e-03, -1.56808659e-01, -9.74798426e-02],\n       [-3.60042751e-02, -1.06608510e-01,  6.48951083e-02, ...,\n         2.74836272e-02, -8.31086561e-02, -1.09950885e-01],\n       [-2.29530483e-02,  7.76250511e-02, -8.90766010e-02, ...,\n        -4.28326130e-02, -7.51021877e-02, -3.38479280e-02],\n       ...,\n       [-9.11356434e-02,  9.69639271e-02,  1.10460892e-01, ...,\n        -1.60995856e-01, -1.52339041e-03,  5.36310226e-02],\n       [-1.00275695e-01,  6.58039600e-02, -1.79283768e-02, ...,\n        -1.26207724e-01, -1.40707284e-01, -1.62662551e-01],\n       [ 1.02944076e-02,  5.56907356e-02,  1.27702951e-04, ...,\n        -1.70709267e-01, -1.55449539e-01, -1.57297805e-01]], dtype=float32)>), (None, <tf.Variable 'dense_169/bias:0' shape=(128,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>), (None, <tf.Variable 'dense_170/kernel:0' shape=(128, 32) dtype=float32, numpy=\narray([[-7.7545837e-02,  8.7927490e-02, -1.6217847e-01, ...,\n        -8.2276911e-03, -4.7364712e-02, -1.9313799e-01],\n       [-8.2969375e-02,  1.6132891e-01, -1.6293742e-01, ...,\n         1.5377656e-02,  1.0528779e-01,  1.3304105e-01],\n       [-1.3354075e-01, -1.8542416e-01, -1.4812668e-01, ...,\n        -8.3281808e-02,  1.2046054e-02, -1.0734460e-01],\n       ...,\n       [ 2.1016523e-02,  1.4211819e-02, -1.2673438e-04, ...,\n         1.3758963e-01, -4.7146827e-02, -3.5619959e-02],\n       [-6.7070842e-02, -1.4825407e-01,  1.9334108e-02, ...,\n        -1.5477800e-01, -1.4473243e-01, -5.6041926e-03],\n       [-1.7265388e-01, -5.8268011e-02,  8.8322967e-02, ...,\n         9.1381699e-02, -1.2689695e-01, -1.3943017e-04]], dtype=float32)>), (None, <tf.Variable 'dense_170/bias:0' shape=(32,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n      dtype=float32)>), (None, <tf.Variable 'dense_171/kernel:0' shape=(32, 3) dtype=float32, numpy=\narray([[-0.14802611, -0.17663312,  0.24846485],\n       [ 0.14170894,  0.20962772, -0.2235752 ],\n       [ 0.25409856, -0.142681  , -0.35423818],\n       [-0.35873434, -0.22375527,  0.30103424],\n       [ 0.03979909, -0.06450826, -0.08402258],\n       [-0.24260809,  0.31510583,  0.25095245],\n       [-0.26781625,  0.34018192,  0.04174289],\n       [-0.09700334,  0.07669389, -0.356626  ],\n       [-0.1723568 , -0.18671633, -0.40805772],\n       [ 0.30375198, -0.09862858, -0.19336556],\n       [ 0.37528083, -0.03854156, -0.1912805 ],\n       [-0.31775108,  0.20650467, -0.33391097],\n       [ 0.27144143,  0.4087684 , -0.1812588 ],\n       [ 0.2466388 ,  0.34021053,  0.09756497],\n       [ 0.41183266,  0.2655494 , -0.15584153],\n       [-0.13322464, -0.11051285,  0.13289544],\n       [-0.33438343, -0.12576783,  0.40554455],\n       [ 0.37565777, -0.38698402,  0.24261996],\n       [-0.39886266,  0.00347713,  0.04457262],\n       [-0.4079673 , -0.17909843, -0.28399962],\n       [-0.0095993 , -0.1248005 , -0.09170592],\n       [-0.19293664,  0.17376962,  0.30902448],\n       [ 0.12625852, -0.22401735,  0.01145673],\n       [-0.34048152,  0.30327544, -0.11391011],\n       [-0.25769645, -0.03775835, -0.1359928 ],\n       [ 0.29896125, -0.25628224, -0.38777888],\n       [-0.2455024 ,  0.13248578, -0.10831308],\n       [-0.3034248 ,  0.37395015,  0.04530638],\n       [-0.2807859 ,  0.40852126, -0.06248668],\n       [ 0.4078144 ,  0.16696164,  0.089964  ],\n       [ 0.09533539, -0.20072375,  0.20853624],\n       [-0.39300898, -0.2615564 , -0.18440326]], dtype=float32)>), (None, <tf.Variable 'dense_171/bias:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>))."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "\n",
    "# data=load_iris()\n",
    "# iris_target=data.target\n",
    "# iris_data=np.float32(data.data)\n",
    "# iris_target=np.float32(tf.keras.utils.to_categorical(iris_target,num_classes=3))\n",
    "data_1 = pd.read_excel('/Users/kuzaowuwei/Desktop/2022//3/data/bitcoin_indicator.xlsx')\n",
    "data_2 = pd.read_excel('/Users/kuzaowuwei/Desktop/2022//3/data/gold_indicator.xlsx')\n",
    "data_3 = pd.read_excel('/Users/kuzaowuwei/Desktop/2022//3/data/price_volatility.xlsx')\n",
    "data_indicator = np.concatenate((data_1.values,data_2.values),axis=1)\n",
    "target_u = data_3[['u_gold','u_bitcoin']].values[10:]\n",
    "batch_size = 50\n",
    "data_indicator=tf.data.Dataset.from_tensor_slices(data_indicator).batch(batch_size)\n",
    "target_u=tf.data.Dataset.from_tensor_slices(target_u).batch(batch_size)\n",
    "a1 = 0.01\n",
    "a2 = 0.02\n",
    "\n",
    "\n",
    "model=tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Dense(64,activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(128,activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(32,activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(3,activation='softmax'))\n",
    "opt=tf.optimizers.Adam(1e-3)\n",
    "for epoch in range(1000):\n",
    "    for _data,lable in zip(data_indicator,target_u):\n",
    "        with tf.GradientTape() as tape:\n",
    "            logits=model(_data)\n",
    "            # print(lable.shape, lable)\n",
    "            \n",
    "            # loss value needs to be modified\n",
    "            # loss  batch_size \n",
    "            # lable 50,2; logits 50,3 \n",
    "            \n",
    "            # value = np.zeros(batch_size)\n",
    "            # value[0] = 1\n",
    "            \n",
    "            # for t in range(batch_size-1):\n",
    "            #     u = np.zeros((1,3))\n",
    "            #     u[:,1:] = lable[t+1]\n",
    "            #     u = u.reshape(3,1)\n",
    "            #     prob = np.array(logits[t+1]).reshape(1,3)\n",
    "            #     transaction_cost = abs(lable[t+1][0]) * a1 + abs(lable[t+1][1]) * a2 \n",
    "            #     # print((value[t] * prob).dot(u+1))\n",
    "            #     # print(value[t] * prob * (u+1) - transaction_cost)\n",
    "\n",
    "            #     value[t+1] = (value[t] * prob).dot(u+1) - transaction_cost\n",
    "\n",
    "            # TR = value[batch_size-1] - value[0]\n",
    "            # loss_value = 1/TR\n",
    "            # # loss_value = tf.Tensor(loss_value,value_index=(), dtype=tf.float32)\n",
    "            # loss_value = tf.reduce_mean(tf.convert_to_tensor(loss_value,dtype=tf.float32))\n",
    "\n",
    "            def get_loss(y_true, y_pred):\n",
    "                batch_size = 50\n",
    "                value = np.zeros(batch_size)\n",
    "                value[0] = 1\n",
    "                for t in range(batch_size-1):\n",
    "                    u = np.zeros((1,3))\n",
    "                    u[:,1:] = lable[t+1]\n",
    "                    u = u.reshape(3,1)\n",
    "                    prob = np.array(logits[t+1]).reshape(1,3)\n",
    "                    transaction_cost = abs(lable[t+1][0]) * a1 + abs(lable[t+1][1]) * a2 \n",
    "                    # print((value[t] * prob).dot(u+1))\n",
    "                    # print(value[t] * prob * (u+1) - transaction_cost)\n",
    "\n",
    "                    value[t+1] = (value[t] * prob).dot(u+1) - transaction_cost\n",
    "\n",
    "                TR = value[batch_size-1] - value[0]\n",
    "                loss_value = 1/TR\n",
    "                # loss_value = tf.Tensor(loss_value,value_index=(), dtype=tf.float32)\n",
    "                loss_value = tf.reduce_mean(tf.convert_to_tensor(loss_value,dtype=tf.float32))              \n",
    "                return loss_value\n",
    "\n",
    "            loss_value = get_loss(lable,logits)\n",
    "            # loss_value = tf.Tensor(loss_value)\n",
    "            # loss_value=tf.reduce_mean(tf.keras.losses.categorical_crossentropy(\n",
    "            #         y_true=lable,y_pred=logits))\n",
    "            print('loss value:', loss_value)\n",
    "\n",
    "            grads=tape.gradient(loss_value,model.trainable_variables)\n",
    "            opt.apply_gradients(zip(grads,model.trainable_variables))\n",
    "    print('Training loss is:',loss_value.numpy() )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 3)\n",
      "(50, 3)\n",
      "(50, 3)\n"
     ]
    }
   ],
   "source": [
    "for _data,lable in zip(iris_data,iris_target):\n",
    "    print(lable.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 2., 2.])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ones(3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "571121258990c3076cccab8cdb8a1b847cf35af00b003ed76f2ada50f9eb31f3"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('py4tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
